{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "570ea62c-53a6-41e9-84a8-574aeccd4ee7",
   "metadata": {},
   "source": [
    "# Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f676ac-37ae-4b75-b284-75d9cae7f25f",
   "metadata": {},
   "source": [
    "# Assignments:\n",
    "\n",
    "1. Add another feature called  Preferential Attachment  with followers and followees data of vertex. you can check about Preferential Attachment in below link\n",
    "http://be.amazd.com/link-prediction/ <br>\n",
    "2. Add  feature called svd_dot. you can calculate svd_dot as Dot product between sourse node svd and destination node svd features.  you can read about this in below pdf \n",
    "https://storage.googleapis.com/kaggle-forum-message-attachments/2594/supervised_link_prediction.pdf<br>\n",
    "3. Tune hyperparameters for XG boost with all these features and check the error metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b772b0-4f50-45c2-b811-8949c8341a8e",
   "metadata": {},
   "source": [
    "### 1.  Preferential Attachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13097007-d7fb-431d-a40c-543564ced8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f3ac9dd-8794-4380-b457-37beb4f5fac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extration(data):\n",
    "    \n",
    "    # Preprosseing\n",
    "    \n",
    "    node_follower =dict()\n",
    "    for idx,rows in tqdm(data.iterrows(),total=len(data)):\n",
    "        node_follower[rows['source_node']] = rows['num_followers_s']\n",
    "    features = []\n",
    "    \n",
    "    for idx,rows in tqdm(data.iterrows(),total=len(data)):\n",
    "        feat1 = [rows['num_followees_s']*rows['num_followees_d'] ]\n",
    "        if node_follower.get(rows['destination_node']) is None:\n",
    "            feat1.append(0)\n",
    "        else:\n",
    "            feat1.append(node_follower[rows['destination_node']]*rows['num_followers_s'])\n",
    "        u_s = np.array(rows[['svd_u_s_1', 'svd_u_s_2', 'svd_u_s_3', 'svd_u_s_4','svd_u_s_5', 'svd_u_s_6']])\n",
    "        u_d = np.array(rows[['svd_u_d_1', 'svd_u_d_2', 'svd_u_d_3','svd_u_d_4', 'svd_u_d_5', 'svd_u_d_6']])\n",
    "        v_s = np.array(rows[['svd_v_s_1', 'svd_v_s_2','svd_v_s_3', 'svd_v_s_4', 'svd_v_s_5', 'svd_v_s_6']])\n",
    "        v_d = np.array(rows[['svd_v_d_1','svd_v_d_2', 'svd_v_d_3', 'svd_v_d_4', 'svd_v_d_5', 'svd_v_d_6']])\n",
    "        feat2 = [np.dot(u_d,u_s)/(np.linalg.norm(u_d)*np.linalg.norm(u_s)),np.dot(v_s,v_d)/(np.linalg.norm(v_d)*np.linalg.norm(v_s))]# should we normalize\n",
    "        feat1.extend(feat2)\n",
    "        features.append(feat1)\n",
    "    pd_features = pd.DataFrame(features,columns=[\"preferentail_followees\",\"preferential_follower\",\"svd_dot_u\",\"svd_dot_v\"])\n",
    "    \n",
    "    return pd.concat([data,pd_features],axis=1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3f202fc-b257-4d83-825b-d28656487b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_train = pd.read_hdf('data/fea_sample/storage_sample_stage4.h5', 'train_df',mode='r')\n",
    "df_final_test = pd.read_hdf('data/fea_sample/storage_sample_stage4.h5', 'test_df',mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae25fb9b-d89d-4c17-833f-e976e1f800c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100002/100002 [00:05<00:00, 18876.82it/s]\n",
      "  0%|                                                                                                                                             | 0/100002 [00:00<?, ?it/s]/scratch/sisodiya.bhoomeendra/fb/lib/python3.7/site-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in double_scalars\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100002/100002 [02:40<00:00, 623.24it/s]\n"
     ]
    }
   ],
   "source": [
    "feat = feature_extration(df_final_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dde75eb5-242f-4a95-9181-ca0b76e3dd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    50050\n",
       "0    49952\n",
       "Name: indicator_link, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat['indicator_link'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f7b9dd3-31d8-49c4-8b2c-a1704caa6bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50002/50002 [00:02<00:00, 18825.76it/s]\n",
      "  0%|                                                                                                                                              | 0/50002 [00:00<?, ?it/s]/scratch/sisodiya.bhoomeendra/fb/lib/python3.7/site-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in double_scalars\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50002/50002 [01:21<00:00, 617.18it/s]\n"
     ]
    }
   ],
   "source": [
    "test = feature_extration(df_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66f1fa75-602c-46b9-bbfa-0f455ceec2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25046\n",
       "1    24956\n",
       "Name: indicator_link, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['indicator_link'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb6246ca-c8b2-4f18-bb06-d7e682e675b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf = pd.HDFStore('./data/fea_sample/storage_sample_stage5.h5')\n",
    "hdf.put('train_df',feat, format='table', data_columns=True)\n",
    "hdf.put('test_df',test, format='table', data_columns=True)\n",
    "hdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b19bd0-5474-4704-9e74-9eec4103b7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
