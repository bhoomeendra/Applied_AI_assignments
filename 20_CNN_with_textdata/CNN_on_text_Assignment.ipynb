{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2851e259-5b4e-4d7a-ae8b-a4aa49d8fb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point 1\n",
    "import re\n",
    "import nltk\n",
    "from tqdm import tqdm \n",
    "\n",
    "email_rx = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "tag_re = r'<\\s*.*?\\s*>'\n",
    "bracket_re = r'\\(\\s*.*?\\s*\\)'\n",
    "colan_rx = r'\\w*\\s*:'\n",
    "underscore_re = r'_+\\w*|\\w*_'\n",
    "\n",
    "def is_email(email):\n",
    "    if(re.fullmatch(email_rx, email)):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clean_email(email_list):\n",
    "    final_output = ''\n",
    "    # print(email_list)\n",
    "    for email in email_list:\n",
    "        process_email = [ txt for txt in email.split(\"@\")[1].split('.') if len(txt) >2 and txt!='com']\n",
    "        for token in process_email:\n",
    "            final_output += token + ' '\n",
    "        # print(email,process_email,final_output)\n",
    "    return final_output\n",
    "# Point 2\n",
    "def clean_subject(line):\n",
    "    subject = re.sub(colan_rx,'',line)\n",
    "    subject = re.sub(pattern='\\n',repl=' ',string=subject)\n",
    "    subject = re.sub(pattern='\\t',repl=' ',string=subject)\n",
    "    subject = re.sub(pattern=r'[^\\w+|\\s*]',repl = '', string =subject)\n",
    "    # print(line,\"\\n\",subject)\n",
    "    return subject.strip()\n",
    "\n",
    "def remove_nested_parentheses(s):\n",
    "    ret = ''\n",
    "    skip = 0\n",
    "    for i in s:\n",
    "        if i == '(':\n",
    "            skip += 1\n",
    "        elif i == ')'and skip > 0:\n",
    "            skip -= 1\n",
    "        elif skip == 0:\n",
    "            ret += i\n",
    "    return ret\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "def remove_person_and_comdine(text):\n",
    "    # tokenize then do pos then pass it to ne_chuking\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    pos_tagged = nltk.pos_tag(tokens)\n",
    "    id_txt = nltk.chunk.ne_chunk(pos_tagged)\n",
    "    output = ''\n",
    "    for elm in list(id_txt):\n",
    "        if type(elm) is tuple:\n",
    "            if elm[1] != 'PERSON':\n",
    "                output += elm[0] + ' '\n",
    "        else:\n",
    "            if elm.label() != 'PERSON':\n",
    "                txt = elm.leaves()\n",
    "                processed = ''\n",
    "                for word in txt:\n",
    "                    processed += word[0] + '_'\n",
    "                if processed[-1] =='_':\n",
    "                    output += processed[:-1]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a6e797e-afbe-4edf-8ec1-8a258662a632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    email_list  = re.findall(email_rx,text)# Point 1\n",
    "    list_of_preproessed_emails = clean_email(email_list)# Point 1\n",
    "    Input_Text = text.lower()\n",
    "    Input_Text = Input_Text.replace('\\\\n','\\n')\n",
    "    Input_Text = re.sub(email_rx,\" \",Input_Text)# Point 2\n",
    "\n",
    "    # print(\"Emails Removed : \\n\",Input_Text)\n",
    "\n",
    "    p_text = ''# Processed text\n",
    "    subject = ''\n",
    "    for line in Input_Text.split('\\n'):\n",
    "        if len(line) > 0:\n",
    "            if line.find(\"subject:\") != -1:\n",
    "                subject += clean_subject(line)# Point 3\n",
    "                p_text+= ' '# Point 4\n",
    "            else:\n",
    "                if line.find(\"write to:\") == -1 and line.find(\"from:\") == -1:# Point 5\n",
    "                    p_text += line + ' '\n",
    "    # temp = p_text\n",
    "    p_text = re.sub(r'\\s+',' ',p_text)\n",
    "    p_text = re.sub(pattern=tag_re,repl=' ',string=p_text)# Point 6\n",
    "    p_text = remove_nested_parentheses(p_text)# Point 7\n",
    "    p_text = re.sub(pattern='\\n',repl=' ',string=p_text)# Point 8\n",
    "    p_text = re.sub(pattern='\\t',repl=' ',string=p_text)# Point 8\n",
    "    p_text = p_text.replace('\\\\',' ')# Point 8\n",
    "    # print(\"Tags brackets \\\\n \\\\t \\\\ is removed : \",p_text)\n",
    "    p_text = re.sub(r'\\s+',' ',p_text)\n",
    "    final_text = ''\n",
    "    for word in p_text.split(' '):# Point 9\n",
    "\n",
    "        if len(word) > 0 and word[-1] != ':':\n",
    "            final_text+= word + ' '\n",
    "    # print(\"Words ending with colan removed : \\n\",final_text)\n",
    "    final_text = decontracted(final_text)# Point 10\n",
    "    # print(\"Words decontracted :\\n\",final_text)\n",
    "    # Chunking\n",
    "    temp = final_text\n",
    "    final_text = re.sub(r'[^\\w+|\\s*]',' ',final_text)\n",
    "    final_text = remove_person_and_comdine(final_text)\n",
    "    final_text = re.sub(pattern='[0-9]+',repl=' ',string=final_text)# Point 13\n",
    "    final_text = re.sub(r'\\s+',' ',final_text)\n",
    "    final_text = re.sub(pattern=underscore_re,repl='',string=final_text)# Point 14\n",
    "    p_text = ''\n",
    "    for word in final_text.split(\" \"):\n",
    "        if len(word)>14 or len(word)<3:\n",
    "            continue\n",
    "        else:\n",
    "            if re.fullmatch('[a-zA-Z_]+',word) is not None:\n",
    "                p_text += word + ' '\n",
    "    return [list_of_preproessed_emails,subject,p_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ada4e6b9-a622-40a1-80ae-0313e9635384",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home2/sisodiya.bhoomendra/Applied_ai/21_CNN_with_textdata/documents/alt.atheism_49960.txt\"\n",
    "input_text = str(open(file_path,'rb').read())\n",
    "email,subject,text = clean_text(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80bde212-f921-4ac0-9476-466555f1a7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mantis netcom mantis '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af0f5f74-fb60-4580-9e05-0a51a30fdc71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'altatheism  atheist resources'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ec421b0-b853-469d-b78e-d53ad79d0286",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'atheism resources resources december atheist resources addresses atheist organizations usa freedom from religion foundation darwin fish bumper stickers and assorted other atheist paraphernalia are available from the freedom from religion foundation the evolution designs evolution designs sell the darwin fish fish symbol like the ones christians stick their cars but with feet and the word darwin written inside the deluxe moulded plastic fish postpaid the people the san francisco bay area can get darwin fish from lynn gold try mailing for net people who lynn directly the price per fish american atheist press aap publish various atheist books critiques the bible lists biblical contradictions and one such book the bible handbook ball and foote american atheist press isbn edition bible contradictions absurdities atrocities immoralities contains ball the bible contradicts itself aap based the king james version the bible cameron road austin prometheus books sell books including haught holy horrors alternate address prometheus books glenn drive buffalo african americans for humanism organization promoting black secular humanism and uncovering the history black freethought they publish quarterly newsletter aah examiner buffalo united kingdom rationalist press association national secular society islington high street holloway road london london british humanist association south place ethical society lamb conduit passage conway hall london red lion square london fax the national secular society publish the freethinker monthly magazine founded germany ibka bund der und atheisten postfach berlin germany ibka publish miz miz vertrieb postfach berlin germany ibdk ucherdienst der postfach hannover germany books fiction thomas disch the santa claus compromise short story the ultimate proof that santa exists all characters and events are fictitious any similarity living dead gods well walter miller canticle for leibowitz one gem this post atomic doomsday novel the monks who spent their lives copying blueprints from saint leibowitz filling the sheets paper with ink and leaving white lines and letters edgar pangborn davy post atomic doomsday novel set clerical states the church for example forbids that anyone produce describe use any substance containing atoms philip dick philip dick dick wrote many philosophical and thought provoking short stories and novels his stories are bizarre times but very approachable wrote mainly but wrote about people truth and religion rather than technology although often believed that had met some sort god remained sceptical amongst his novels the following are some galactic pot healer fallible alien deity summons group earth craftsmen and women remote planet raise giant cathedral from beneath the oceans when the deity begins demand faith from the earthers pot healer joe fernwright unable comply polished ironic and amusing novel maze death noteworthy for its description technology based religion valis the schizophrenic hero searches for the hidden mysteries gnostic christianity after reality fired into his brain pink laser beam unknown but possibly divine origin accompanied his dogmatic and dismissively atheist friend and assorted other odd characters the divine invasion god invades earth making young woman pregnant she returns from another star system unfortunately she terminally ill and must assisted dead man whose brain wired hour easy listening music margaret atwood the handmaid tale story based the premise that the congress mysteriously assassinated and quickly take charge the nation set right again the book the diary woman life she tries live under the new christian theocracy women right own property revoked and their bank accounts are closed sinful luxuries are outlawed and the radio only used for readings from the bible crimes are punished doctors who performed legal abortions the old world are hunted down and hanged atwood writing style difficult get used first but the tale grows more and more chilling goes various authors the bible this somewhat dull and rambling work has often been criticized however probably worth reading only that you will know what all the fuss about exists many different versions make sure you get the one true version books non fiction peter rosa vicars christ bantam press although rosa seems christian even catholic this very enlighting history papal immoralities adulteries fallacies etc michael martin philosophical justification temple university press philadelphia usa detailed and scholarly justification atheism contains outstanding appendix defining terminology and usage this tendentious area argues both for negative atheism and also for positive atheism includes great refutations the most challenging arguments for god particular attention paid refuting contempory theists such platinga and swinburne pages isbn the case against christianity temple university press comprehensive critique christianity which considers the best contemporary defences christianity and demonstrates that they are unsupportable and incoherent pages isbn james turner without god without creed the johns hopkins university press baltimore usa subtitled the origins unbelief america examines the way which unbelief became mainstream alternative world view focusses the period and while considering france and britain the emphasis american and particularly new england developments neither religious history secularization atheism without god without creed rather the intellectual history the fate single idea the belief that god exists pages isbn george seldes the great thoughts ballantine books new york usa dictionary quotations different kind concentrating statements and writings which explicitly implicitly present the person philosophy and world view includes obscure opinions from many people for some popular observations traces the way which various people expressed and twisted the idea over the centuries quite number the quotations are derived from cardiff what great men think religion and noyes views religion pages isbn richard swinburne the existence god clarendon paperbacks oxford this book the second volume trilogy that began with the coherence theism and was concluded with faith and reason this work swinburne attempts construct series inductive arguments for the existence god his arguments which are somewhat tendentious and rely upon the imputation late century western christian values and aesthetics god which supposedly simple can conceived were decisively rejected mackie the miracle theism the revised edition the existence god swinburne includes appendix which makes somewhat incoherent attempt rebut mackie mackie the miracle theism oxford this volume contains comprehensive review the principal arguments for and against the existence god ranges from the classical philosophical positions descartes anselm berkeley hume through the moral arguments newman kant and sidgwick the recent restatements the classical theses plantinga and swinburne also addresses those positions which push the concept god beyond the realm the rational such those kierkegaard kung and philips well replacements for god such lelie axiarchism the book delight read less formalistic and better written than martin works and refreshingly direct when compared with the hand waving swinburne james haught holy illustrated history religious murder and madness prometheus books looks religious persecution from ancient times the present day and not only christians library congress catalog card number norm allen african american anthology see the listing for african americans for humanism above gordon stein anthology atheism and rationalism prometheus books anthology covering wide range subjects including nothe devil evil and morality and nothe history freethought comprehensive bibliography edmund cohen the mind the bible believer prometheus books study why people become christian and what effect has them net resources there small mail based archive server mantis which carries archives old alt atheism moderated articles and assorted other files for more information send mail saying help send atheism index and will mail back reply mathew xff '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "160f43ae-0c11-4cac-8e2f-15173d76e27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18828/18828 [16:18<00:00, 19.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the number of file which i am not able to open  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm \n",
    "ada_path = '/home2/sisodiya.bhoomendra/Applied_ai/21_CNN_with_textdata/documents/*'\n",
    "processed = []\n",
    "file_paths = []\n",
    "count = 0\n",
    "label = []\n",
    "    \n",
    "for file_path in tqdm(glob(ada_path)):\n",
    "    file_paths.append(file_path.split('/')[-1])\n",
    "    # print(file_path)\n",
    "    file = open(file_path,'rb')\n",
    "    try:\n",
    "        input_text = str(file.read())\n",
    "        label = file_path.split('/')[-1].split('_')[0]\n",
    "        email,subject,text = clean_text(input_text)\n",
    "        processed.append([text , subject ,email ,label])\n",
    "        file.close()\n",
    "    except BaseException as e:\n",
    "        count+=1\n",
    "        file.close()\n",
    "        continue\n",
    "print(\"These are the number of file which i am not able to open \",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2e924d72-91f9-4054-8d42-6dcca6639b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "importdata_set_prepandas as pd\n",
    "df  = pd.DataFrame(processed)\n",
    "df.head()\n",
    "df.to_csv(\"preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6251f98f-b3c4-4339-85c5-27ce49947b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "table = pd.read_csv('preprocessed.csv')\n",
    "df_processed = table.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43e13491-ca3d-42e9-9d3c-ad691223317b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 'article markus maier well searching for the windows logo know the picture when start windows some suitable grafics format like gif jpg windows system vgalogo rle memory serves correctly rle compressed bmp format readable wingif paintshop pro paint and god knows how many other programs mike mattix agricultural group monsanto box luling internet ',\n",
       " 'need windowslogo',\n",
       " 'access digex net access digex rzmain uni-ulm bigez monsanto ',\n",
       " 'comp.os.ms-windows.misc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "763c07ec-7fb4-47ee-af5f-462ce99a3504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_set_prep(processed):\n",
    "    X = []\n",
    "    y = []\n",
    "    thresh = 400\n",
    "    for x in tqdm(processed):\n",
    "        text = ''\n",
    "        y.append(x[4])\n",
    "        if type(x[2]) is str:\n",
    "            text += x[2] + ' '\n",
    "        if type(x[1]) is str:\n",
    "            text += x[1] + ' '\n",
    "        if type(x[3]) is str:\n",
    "            text += x[3]\n",
    "        text = re.sub('\\s+',' ',text)\n",
    "        # print(text)\n",
    "        if len(text.split(' ')) > thresh:\n",
    "            final = ''\n",
    "            count = 0 \n",
    "            for word in text.split(' '):\n",
    "                final += word+' '\n",
    "                count += 1\n",
    "                if count>= thresh:\n",
    "                    break\n",
    "            X.append(final.strip())\n",
    "        else:\n",
    "            X.append(text)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4248a629-50d6-4bcb-8554-a2fc604c84be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18828/18828 [00:01<00:00, 13373.37it/s]\n"
     ]
    }
   ],
   "source": [
    "X,y = data_set_prep(df_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2fafa05-c3d3-4049-a013-dab4b71142f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 400)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = [len(p.split(' ')) for p in X]\n",
    "min(lengths),max(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3acbb149-d855-40d2-86b0-e45cab986c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc',\n",
       "       'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware',\n",
       "       'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles',\n",
       "       'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt',\n",
       "       'sci.electronics', 'sci.med', 'sci.space',\n",
       "       'soc.religion.christian', 'talk.politics.guns',\n",
       "       'talk.politics.mideast', 'talk.politics.misc',\n",
       "       'talk.religion.misc'], dtype='<U24')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d0b1054-0270-4ea3-a8ea-c9f00c8338ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "550a596e-4612-4b81-beb0-edb5cd171b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "353007b5-06df-4098-9f4f-06ea31407f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b7d83b1-34cb-4fc7-bb42-5f8aad31c124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79026"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tokenizer.word_index\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "591449da-d7e0-4800-b696-84faeb028116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18828, 403)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X = tokenizer.texts_to_sequences(X)\n",
    "padded_data = tf.keras.preprocessing.sequence.pad_sequences(data_X, padding='post')\n",
    "padded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86f35506-6a6d-4bea-ad1c-21d8edc6af1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "oneHot = OneHotEncoder(handle_unknown='ignore')\n",
    "y_np = np.array(y)\n",
    "y_onehot = oneHot.fit_transform(y_np.reshape(-1,1))# Returs a sparce matrix\n",
    "y_final = y_onehot.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "607524ee-7c6e-4cd0-a2d7-fbd174a1a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(padded_data,y_final,stratify=y_final,test_size=0.2)\n",
    "X_train,X_cv,y_train,y_cv = train_test_split(X_train,y_train,stratify=y_train,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e24ead9-dd7e-4652-9650-60ea01bb80a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13555, 403), (3766, 403), (13555, 20), (3766, 20))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0036f7db-fb27-47f2-9689-d36634100fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:10, 37988.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. 400000  words loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def loadGloveModel(gloveFile):\n",
    "    print (\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r', encoding=\"utf8\")\n",
    "    model = {}\n",
    "    for line in tqdm(f):\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print (\"Done.\",len(model),\" words loaded!\")\n",
    "    return model\n",
    "glove_emb = loadGloveModel('glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa28a2ec-96da-49b6-b30a-f1a4a93e8241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size:  79027\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(a)+1\n",
    "dims = glove_emb['the'].shape[0]\n",
    "seq_length = padded_data.shape[1]\n",
    "print(\"Vocab Size: \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "703509c1-915b-45a8-9f27-5efbdb42d4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words found and there ratio :  51630 0.6533210168676529\n"
     ]
    }
   ],
   "source": [
    "embeding = np.zeros((vocab_size,dims))\n",
    "count = 0\n",
    "not_found = [] \n",
    "for word,idx in a.items():\n",
    "    if glove_emb.get(word) is not None:\n",
    "        count+=1\n",
    "        embeding[idx] = glove_emb[word]\n",
    "    else:\n",
    "        not_found.append(word)\n",
    "print(\"Words found and there ratio : \",count,count/vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f35a9f36-c90d-4377-9d37-cce19e56ad21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18828, 403)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6b8e82d-469a-444b-9acb-1eb37a7c4c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79027, 100)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41eb327-e8a3-4158-8dc2-2a6443835b4f",
   "metadata": {},
   "source": [
    "# Use 840B token glove next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9021a85-ea4e-4bbe-a7cf-baff5eac7705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 02:05:29.110220: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-17 02:05:29.629155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9651 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:03:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "input_seq =  tf.keras.layers.Input(shape=(padded_data.shape[1],))\n",
    "embbeding_layer = tf.keras.layers.Embedding(input_dim=vocab_size,output_dim = dims,weights=[embeding],input_length=seq_length, trainable=False)(input_seq)\n",
    "\n",
    "layer_1_conv_4 = tf.keras.layers.Conv1D(filters = 5, kernel_size = 3, strides=1, activation='relu')(embbeding_layer)\n",
    "layer_1_conv_2 = tf.keras.layers.Conv1D(filters = 5, kernel_size = 2, strides=1, activation='relu')(embbeding_layer)\n",
    "layer_1_conv_1 = tf.keras.layers.Conv1D(filters = 5, kernel_size = 1, strides=1, activation='relu')(embbeding_layer)\n",
    "\n",
    "layer_2_concat = tf.keras.layers.concatenate([layer_1_conv_4, layer_1_conv_2, layer_1_conv_1],axis=1)\n",
    "max_pool_layer_1 = tf.keras.layers.MaxPool1D( pool_size=4,strides=1)(layer_2_concat)\n",
    "\n",
    "layer_2_conv_4 = tf.keras.layers.Conv1D(filters = 10, kernel_size = 4, strides=1, activation='relu')(max_pool_layer_1)\n",
    "layer_2_conv_2 = tf.keras.layers.Conv1D(filters = 10, kernel_size = 3, strides=1, activation='relu')(max_pool_layer_1)\n",
    "layer_2_conv_1 = tf.keras.layers.Conv1D(filters = 10, kernel_size = 2, strides=1, activation='relu')(max_pool_layer_1)\n",
    "\n",
    "layer_2_concat = tf.keras.layers.concatenate([layer_2_conv_4, layer_2_conv_2, layer_2_conv_1],axis=1)\n",
    "max_pool_layer_2 = tf.keras.layers.MaxPool1D( pool_size = 3,strides=1)(layer_2_concat)\n",
    "\n",
    "layer_2_conv_f = tf.keras.layers.Conv1D(filters = 1, kernel_size = 10, strides=1, activation='relu')(max_pool_layer_2)\n",
    "flat_layer = tf.keras.layers.Flatten()(layer_2_conv_f)\n",
    "\n",
    "dense_layer_1 = tf.keras.layers.Dense(32,activation='relu')(flat_layer)\n",
    "dropout_layer = tf.keras.layers.Dropout(.5)(dense_layer_1)\n",
    "output_layer = tf.keras.layers.Dense(20,activation='softmax')(dropout_layer)\n",
    "\n",
    "model = tf.keras.Model(input_seq,output_layer)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01,momentum=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8bee214-7fab-4292-a7de-b4b952554b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 403)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 403, 100)     7902700     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 401, 5)       1505        ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 402, 5)       1005        ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 403, 5)       505         ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1206, 5)      0           ['conv1d[0][0]',                 \n",
      "                                                                  'conv1d_1[0][0]',               \n",
      "                                                                  'conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 1203, 5)      0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 1200, 10)     210         ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 1201, 10)     160         ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 1202, 10)     110         ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 3603, 10)     0           ['conv1d_3[0][0]',               \n",
      "                                                                  'conv1d_4[0][0]',               \n",
      "                                                                  'conv1d_5[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 3601, 10)    0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 3592, 1)      101         ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 3592)         0           ['conv1d_6[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32)           114976      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 32)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 20)           660         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,021,932\n",
      "Trainable params: 119,232\n",
      "Non-trainable params: 7,902,700\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy',metrics=['categorical_accuracy',tf.keras.metrics.Recall(thresholds=0.05),tf.keras.metrics.Precision(thresholds=0.05)])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e71905d9-2680-45d8-8c2a-bbb8c30ea65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "class ModelMetric(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self,validation_data):\n",
    "        self.x_cv = validation_data[0]\n",
    "        self.y_cv = validation_data[1]\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        ## on begin of training, we are creating a instance varible called history\n",
    "        ## it is a dict with keys [loss, acc, val_loss, val_acc]\n",
    "        self.history={'loss': [],'train_f1_score': [],'val_loss': [],'val_f1_score': [],'f1_score': [],'auc': []}\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        loss = logs.get('loss')\n",
    "        if loss is not None:\n",
    "            if np.isnan(loss) or np.isinf(loss):\n",
    "                print(\"Invalid loss and terminated at epoch {}\".format(epoch))\n",
    "                self.model.stop_training = True\n",
    "        \n",
    "        model_weights = self.model.get_weights()\n",
    "        if model_weights is not None:\n",
    "            if np.any([np.any(np.isnan(x)) for x in model_weights]):\n",
    "                print(\"Invalid weight and terminated at epoch {}\".format(epoch))\n",
    "                self.model.stop_training = True\n",
    "            \n",
    "        if self.model.stop_training == False:\n",
    "            print(\"Model Metric\")\n",
    "            true_positives=0\n",
    "            ## on end of each epoch, we will get logs and update the self.history dict\n",
    "            self.history['loss'].append(logs.get('loss'))\n",
    "            recall = logs.get('recall')\n",
    "            precision= logs.get('precision')\n",
    "            print(\"############## F1 score : \",2*recall*precision/(recall + precision))\n",
    "            val_recall = logs.get('val_recall')\n",
    "            val_precision= logs.get('val_precision')\n",
    "            print(\"############## Validation F1 score : \",2*val_recall*val_precision/(val_recall + val_precision))\n",
    "            if logs.get('val_loss', -1) != -1:\n",
    "                self.history['val_loss'].append(logs.get('val_loss'))\n",
    "            if logs.get('val_f1_score', -1) != -1:\n",
    "                self.history['val_f1_score'].append(logs.get('val_categorical_accuracy'))\n",
    "\n",
    "def lr_setter(epoch,lr):\n",
    "    if epoch%3 == 0:\n",
    "        return lr*(0.95)\n",
    "    return lr\n",
    "\n",
    "logs = ModelMetric((X_cv,y_cv))\n",
    "filepath   = \"./model_save/weights-{epoch:02d}-{val_categorical_accuracy:.4f}.hdf5\"\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=filepath, monitor='val_categorical_accuracy',  verbose=1, save_best_only=True, mode='auto')\n",
    "#lrschedule = tf.keras.callbacks.LearningRateScheduler(lr_setter, verbose=1)\n",
    "#reduce     = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',factor=0.9,patience=3,verbose=1)\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', min_delta=0.005, patience=20, verbose=1)\n",
    "log_dir = os.path.join(\"logs\",'fits', datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1,write_graph=True)\n",
    "all_callbacks = [checkpoint,early_stop,logs,tensorboard_callback]# early_stop checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b85df70-f81e-4b9f-8097-853a07cf613e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.8007 - categorical_accuracy: 0.1117 - recall: 0.6395 - precision: 0.0784\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.12541, saving model to ./model_save/weights-01-0.1254.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.13963227775874873\n",
      "############## Validation F1 score :  0.16660474408121057\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 2.8007 - categorical_accuracy: 0.1117 - recall: 0.6395 - precision: 0.0784 - val_loss: 2.6790 - val_categorical_accuracy: 0.1254 - val_recall: 0.7439 - val_precision: 0.0938\n",
      "Epoch 2/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 2.7432 - categorical_accuracy: 0.1228 - recall: 0.6528 - precision: 0.0825\n",
      "Epoch 2: val_categorical_accuracy improved from 0.12541 to 0.16058, saving model to ./model_save/weights-02-0.1606.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.14658784367193117\n",
      "############## Validation F1 score :  0.17386109224776142\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.7426 - categorical_accuracy: 0.1228 - recall: 0.6530 - precision: 0.0826 - val_loss: 2.6171 - val_categorical_accuracy: 0.1606 - val_recall: 0.7724 - val_precision: 0.0980\n",
      "Epoch 3/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 2.6923 - categorical_accuracy: 0.1356 - recall: 0.6845 - precision: 0.0878\n",
      "Epoch 3: val_categorical_accuracy improved from 0.16058 to 0.16589, saving model to ./model_save/weights-03-0.1659.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.15570449779547516\n",
      "############## Validation F1 score :  0.18046512159698938\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.6913 - categorical_accuracy: 0.1352 - recall: 0.6847 - precision: 0.0878 - val_loss: 2.5540 - val_categorical_accuracy: 0.1659 - val_recall: 0.7724 - val_precision: 0.1022\n",
      "Epoch 4/100\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 2.6508 - categorical_accuracy: 0.1496 - recall: 0.6933 - precision: 0.0897\n",
      "Epoch 4: val_categorical_accuracy improved from 0.16589 to 0.18115, saving model to ./model_save/weights-04-0.1812.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.1589417414739173\n",
      "############## Validation F1 score :  0.18194606783581083\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 2.6514 - categorical_accuracy: 0.1481 - recall: 0.6932 - precision: 0.0898 - val_loss: 2.5085 - val_categorical_accuracy: 0.1812 - val_recall: 0.7724 - val_precision: 0.1031\n",
      "Epoch 5/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 2.6061 - categorical_accuracy: 0.1587 - recall: 0.7112 - precision: 0.0933\n",
      "Epoch 5: val_categorical_accuracy improved from 0.18115 to 0.21301, saving model to ./model_save/weights-05-0.2130.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.164995420652164\n",
      "############## Validation F1 score :  0.18794000985596232\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.6055 - categorical_accuracy: 0.1589 - recall: 0.7107 - precision: 0.0933 - val_loss: 2.4579 - val_categorical_accuracy: 0.2130 - val_recall: 0.8149 - val_precision: 0.1062\n",
      "Epoch 6/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 2.5552 - categorical_accuracy: 0.1735 - recall: 0.7289 - precision: 0.0971\n",
      "Epoch 6: val_categorical_accuracy did not improve from 0.21301\n",
      "Model Metric\n",
      "############## F1 score :  0.17131318431212358\n",
      "############## Validation F1 score :  0.1918784865779464\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 2.5556 - categorical_accuracy: 0.1731 - recall: 0.7292 - precision: 0.0971 - val_loss: 2.4189 - val_categorical_accuracy: 0.2130 - val_recall: 0.8215 - val_precision: 0.1086\n",
      "Epoch 7/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 2.5252 - categorical_accuracy: 0.1770 - recall: 0.7456 - precision: 0.0999\n",
      "Epoch 7: val_categorical_accuracy improved from 0.21301 to 0.24552, saving model to ./model_save/weights-07-0.2455.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.1764993342539185\n",
      "############## Validation F1 score :  0.1987980392297496\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.5214 - categorical_accuracy: 0.1784 - recall: 0.7460 - precision: 0.1001 - val_loss: 2.3588 - val_categorical_accuracy: 0.2455 - val_recall: 0.8341 - val_precision: 0.1128\n",
      "Epoch 8/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 2.4762 - categorical_accuracy: 0.1898 - recall: 0.7616 - precision: 0.1035\n",
      "Epoch 8: val_categorical_accuracy did not improve from 0.24552\n",
      "Model Metric\n",
      "############## F1 score :  0.18217598619753972\n",
      "############## Validation F1 score :  0.19976535208239107\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 2.4771 - categorical_accuracy: 0.1894 - recall: 0.7615 - precision: 0.1035 - val_loss: 2.3305 - val_categorical_accuracy: 0.2369 - val_recall: 0.8474 - val_precision: 0.1132\n",
      "Epoch 9/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 2.4356 - categorical_accuracy: 0.2020 - recall: 0.7748 - precision: 0.1061\n",
      "Epoch 9: val_categorical_accuracy improved from 0.24552 to 0.25481, saving model to ./model_save/weights-09-0.2548.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.1865578834943685\n",
      "############## Validation F1 score :  0.2038804591272282\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.4369 - categorical_accuracy: 0.2012 - recall: 0.7743 - precision: 0.1061 - val_loss: 2.2809 - val_categorical_accuracy: 0.2548 - val_recall: 0.8646 - val_precision: 0.1156\n",
      "Epoch 10/100\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 2.4094 - categorical_accuracy: 0.2126 - recall: 0.7851 - precision: 0.1080\n",
      "Epoch 10: val_categorical_accuracy improved from 0.25481 to 0.25813, saving model to ./model_save/weights-10-0.2581.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.19042510705948068\n",
      "############## Validation F1 score :  0.21142025755200822\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.4042 - categorical_accuracy: 0.2138 - recall: 0.7857 - precision: 0.1083 - val_loss: 2.2245 - val_categorical_accuracy: 0.2581 - val_recall: 0.8673 - val_precision: 0.1204\n",
      "Epoch 11/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 2.3546 - categorical_accuracy: 0.2279 - recall: 0.7983 - precision: 0.1123\n",
      "Epoch 11: val_categorical_accuracy improved from 0.25813 to 0.28202, saving model to ./model_save/weights-11-0.2820.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.19699022202472447\n",
      "############## Validation F1 score :  0.21518884335656133\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.3537 - categorical_accuracy: 0.2282 - recall: 0.7991 - precision: 0.1123 - val_loss: 2.1867 - val_categorical_accuracy: 0.2820 - val_recall: 0.8752 - val_precision: 0.1227\n",
      "Epoch 12/100\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 2.3155 - categorical_accuracy: 0.2341 - recall: 0.8095 - precision: 0.1150\n",
      "Epoch 12: val_categorical_accuracy did not improve from 0.28202\n",
      "Model Metric\n",
      "############## F1 score :  0.20152719175719822\n",
      "############## Validation F1 score :  0.21846129055238422\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 2.3144 - categorical_accuracy: 0.2342 - recall: 0.8100 - precision: 0.1151 - val_loss: 2.1369 - val_categorical_accuracy: 0.2814 - val_recall: 0.8865 - val_precision: 0.1246\n",
      "Epoch 13/100\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 2.2882 - categorical_accuracy: 0.2388 - recall: 0.8152 - precision: 0.1166\n",
      "Epoch 13: val_categorical_accuracy improved from 0.28202 to 0.29396, saving model to ./model_save/weights-13-0.2940.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.20437362743154483\n",
      "############## Validation F1 score :  0.2264658959980096\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.2855 - categorical_accuracy: 0.2393 - recall: 0.8156 - precision: 0.1168 - val_loss: 2.0792 - val_categorical_accuracy: 0.2940 - val_recall: 0.8932 - val_precision: 0.1297\n",
      "Epoch 14/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 2.2445 - categorical_accuracy: 0.2478 - recall: 0.8297 - precision: 0.1207\n",
      "Epoch 14: val_categorical_accuracy improved from 0.29396 to 0.30192, saving model to ./model_save/weights-14-0.3019.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.21068608316552\n",
      "############## Validation F1 score :  0.22847654558277483\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 2.2431 - categorical_accuracy: 0.2489 - recall: 0.8295 - precision: 0.1207 - val_loss: 2.0557 - val_categorical_accuracy: 0.3019 - val_recall: 0.9131 - val_precision: 0.1306\n",
      "Epoch 15/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 2.2017 - categorical_accuracy: 0.2597 - recall: 0.8372 - precision: 0.1233\n",
      "Epoch 15: val_categorical_accuracy improved from 0.30192 to 0.31918, saving model to ./model_save/weights-15-0.3192.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.21503442073606144\n",
      "############## Validation F1 score :  0.23678755407435356\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.2018 - categorical_accuracy: 0.2589 - recall: 0.8377 - precision: 0.1233 - val_loss: 1.9902 - val_categorical_accuracy: 0.3192 - val_recall: 0.9098 - val_precision: 0.1361\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.1642 - categorical_accuracy: 0.2668 - recall: 0.8430 - precision: 0.1262\n",
      "Epoch 16: val_categorical_accuracy improved from 0.31918 to 0.33444, saving model to ./model_save/weights-16-0.3344.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.21950728397830477\n",
      "############## Validation F1 score :  0.24267708929051096\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 2.1642 - categorical_accuracy: 0.2668 - recall: 0.8430 - precision: 0.1262 - val_loss: 1.9417 - val_categorical_accuracy: 0.3344 - val_recall: 0.9071 - val_precision: 0.1401\n",
      "Epoch 17/100\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 2.1126 - categorical_accuracy: 0.2827 - recall: 0.8504 - precision: 0.1305\n",
      "Epoch 17: val_categorical_accuracy did not improve from 0.33444\n",
      "Model Metric\n",
      "############## F1 score :  0.22618650566797027\n",
      "############## Validation F1 score :  0.2445322695985642\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 2.1129 - categorical_accuracy: 0.2825 - recall: 0.8498 - precision: 0.1305 - val_loss: 1.9324 - val_categorical_accuracy: 0.3338 - val_recall: 0.9237 - val_precision: 0.1409\n",
      "Epoch 18/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 2.0900 - categorical_accuracy: 0.2853 - recall: 0.8568 - precision: 0.1328\n",
      "Epoch 18: val_categorical_accuracy improved from 0.33444 to 0.36364, saving model to ./model_save/weights-18-0.3636.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.23003852416839263\n",
      "############## Validation F1 score :  0.25163875305253275\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.0883 - categorical_accuracy: 0.2859 - recall: 0.8567 - precision: 0.1329 - val_loss: 1.8781 - val_categorical_accuracy: 0.3636 - val_recall: 0.9171 - val_precision: 0.1458\n",
      "Epoch 19/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 2.0667 - categorical_accuracy: 0.2945 - recall: 0.8625 - precision: 0.1354\n",
      "Epoch 19: val_categorical_accuracy improved from 0.36364 to 0.37027, saving model to ./model_save/weights-19-0.3703.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.23413247354932723\n",
      "############## Validation F1 score :  0.2567257371932586\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.0675 - categorical_accuracy: 0.2941 - recall: 0.8624 - precision: 0.1355 - val_loss: 1.8364 - val_categorical_accuracy: 0.3703 - val_recall: 0.9277 - val_precision: 0.1490\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.0304 - categorical_accuracy: 0.3128 - recall: 0.8683 - precision: 0.1386\n",
      "Epoch 20: val_categorical_accuracy improved from 0.37027 to 0.39615, saving model to ./model_save/weights-20-0.3962.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.23897748739211178\n",
      "############## Validation F1 score :  0.2600111651260459\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.0304 - categorical_accuracy: 0.3128 - recall: 0.8683 - precision: 0.1386 - val_loss: 1.8152 - val_categorical_accuracy: 0.3962 - val_recall: 0.9263 - val_precision: 0.1512\n",
      "Epoch 21/100\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 2.0003 - categorical_accuracy: 0.3153 - recall: 0.8671 - precision: 0.1405\n",
      "Epoch 21: val_categorical_accuracy did not improve from 0.39615\n",
      "Model Metric\n",
      "############## F1 score :  0.2421392769854836\n",
      "############## Validation F1 score :  0.26389285053179307\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.9972 - categorical_accuracy: 0.3166 - recall: 0.8681 - precision: 0.1407 - val_loss: 1.7794 - val_categorical_accuracy: 0.3849 - val_recall: 0.9217 - val_precision: 0.1540\n",
      "Epoch 22/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.9724 - categorical_accuracy: 0.3244 - recall: 0.8745 - precision: 0.1428\n",
      "Epoch 22: val_categorical_accuracy improved from 0.39615 to 0.39681, saving model to ./model_save/weights-22-0.3968.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.245640580754522\n",
      "############## Validation F1 score :  0.26990894237801893\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.9736 - categorical_accuracy: 0.3242 - recall: 0.8745 - precision: 0.1429 - val_loss: 1.7398 - val_categorical_accuracy: 0.3968 - val_recall: 0.9244 - val_precision: 0.1580\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.9529 - categorical_accuracy: 0.3278 - recall: 0.8772 - precision: 0.1458\n",
      "Epoch 23: val_categorical_accuracy improved from 0.39681 to 0.41938, saving model to ./model_save/weights-23-0.4194.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.2500368097114349\n",
      "############## Validation F1 score :  0.2758415782809485\n",
      "53/53 [==============================] - 3s 65ms/step - loss: 1.9529 - categorical_accuracy: 0.3278 - recall: 0.8772 - precision: 0.1458 - val_loss: 1.7217 - val_categorical_accuracy: 0.4194 - val_recall: 0.9244 - val_precision: 0.1621\n",
      "Epoch 24/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.9132 - categorical_accuracy: 0.3337 - recall: 0.8839 - precision: 0.1495\n",
      "Epoch 24: val_categorical_accuracy improved from 0.41938 to 0.42402, saving model to ./model_save/weights-24-0.4240.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.25580452850447016\n",
      "############## Validation F1 score :  0.28136958345311897\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.9124 - categorical_accuracy: 0.3335 - recall: 0.8843 - precision: 0.1495 - val_loss: 1.6878 - val_categorical_accuracy: 0.4240 - val_recall: 0.9270 - val_precision: 0.1659\n",
      "Epoch 25/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.8823 - categorical_accuracy: 0.3537 - recall: 0.8831 - precision: 0.1514\n",
      "Epoch 25: val_categorical_accuracy did not improve from 0.42402\n",
      "Model Metric\n",
      "############## F1 score :  0.2584540223383328\n",
      "############## Validation F1 score :  0.2862069057353013\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.8854 - categorical_accuracy: 0.3528 - recall: 0.8827 - precision: 0.1514 - val_loss: 1.6648 - val_categorical_accuracy: 0.4214 - val_recall: 0.9363 - val_precision: 0.1689\n",
      "Epoch 26/100\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 1.8672 - categorical_accuracy: 0.3573 - recall: 0.8857 - precision: 0.1535\n",
      "Epoch 26: val_categorical_accuracy improved from 0.42402 to 0.42734, saving model to ./model_save/weights-26-0.4273.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.2613606609213603\n",
      "############## Validation F1 score :  0.2909540409980427\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.8705 - categorical_accuracy: 0.3556 - recall: 0.8859 - precision: 0.1533 - val_loss: 1.6281 - val_categorical_accuracy: 0.4273 - val_recall: 0.9370 - val_precision: 0.1722\n",
      "Epoch 27/100\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 1.8510 - categorical_accuracy: 0.3576 - recall: 0.8865 - precision: 0.1565\n",
      "Epoch 27: val_categorical_accuracy improved from 0.42734 to 0.43198, saving model to ./model_save/weights-27-0.4320.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.2660491666240327\n",
      "############## Validation F1 score :  0.295146844646739\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 1.8517 - categorical_accuracy: 0.3581 - recall: 0.8879 - precision: 0.1565 - val_loss: 1.6086 - val_categorical_accuracy: 0.4320 - val_recall: 0.9403 - val_precision: 0.1750\n",
      "Epoch 28/100\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 1.8263 - categorical_accuracy: 0.3676 - recall: 0.8884 - precision: 0.1583\n",
      "Epoch 28: val_categorical_accuracy improved from 0.43198 to 0.43862, saving model to ./model_save/weights-28-0.4386.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.2689094340508866\n",
      "############## Validation F1 score :  0.29709365887965183\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.8245 - categorical_accuracy: 0.3676 - recall: 0.8893 - precision: 0.1584 - val_loss: 1.6518 - val_categorical_accuracy: 0.4386 - val_recall: 0.9157 - val_precision: 0.1773\n",
      "Epoch 29/100\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 1.8137 - categorical_accuracy: 0.3739 - recall: 0.8902 - precision: 0.1593\n",
      "Epoch 29: val_categorical_accuracy improved from 0.43862 to 0.44990, saving model to ./model_save/weights-29-0.4499.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.27042828579366546\n",
      "############## Validation F1 score :  0.3035926113542449\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.8139 - categorical_accuracy: 0.3719 - recall: 0.8907 - precision: 0.1594 - val_loss: 1.5827 - val_categorical_accuracy: 0.4499 - val_recall: 0.9336 - val_precision: 0.1813\n",
      "Epoch 30/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.7822 - categorical_accuracy: 0.3731 - recall: 0.8922 - precision: 0.1632\n",
      "Epoch 30: val_categorical_accuracy improved from 0.44990 to 0.45388, saving model to ./model_save/weights-30-0.4539.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.2760430338165586\n",
      "############## Validation F1 score :  0.3078437886438434\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.7809 - categorical_accuracy: 0.3740 - recall: 0.8925 - precision: 0.1633 - val_loss: 1.5525 - val_categorical_accuracy: 0.4539 - val_recall: 0.9336 - val_precision: 0.1843\n",
      "Epoch 31/100\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 1.7602 - categorical_accuracy: 0.3867 - recall: 0.8935 - precision: 0.1659\n",
      "Epoch 31: val_categorical_accuracy did not improve from 0.45388\n",
      "Model Metric\n",
      "############## F1 score :  0.28013180059362436\n",
      "############## Validation F1 score :  0.3087527414456164\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.7592 - categorical_accuracy: 0.3871 - recall: 0.8938 - precision: 0.1661 - val_loss: 1.5489 - val_categorical_accuracy: 0.4519 - val_recall: 0.9363 - val_precision: 0.1849\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.7483 - categorical_accuracy: 0.3876 - recall: 0.8985 - precision: 0.1669\n",
      "Epoch 32: val_categorical_accuracy improved from 0.45388 to 0.47246, saving model to ./model_save/weights-32-0.4725.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.28154655327639616\n",
      "############## Validation F1 score :  0.3147298917058201\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 1.7483 - categorical_accuracy: 0.3876 - recall: 0.8985 - precision: 0.1669 - val_loss: 1.5207 - val_categorical_accuracy: 0.4725 - val_recall: 0.9336 - val_precision: 0.1893\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.7331 - categorical_accuracy: 0.3883 - recall: 0.8988 - precision: 0.1684\n",
      "Epoch 33: val_categorical_accuracy improved from 0.47246 to 0.47512, saving model to ./model_save/weights-33-0.4751.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.2835926847770739\n",
      "############## Validation F1 score :  0.31573084165895005\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 1.7331 - categorical_accuracy: 0.3883 - recall: 0.8988 - precision: 0.1684 - val_loss: 1.5078 - val_categorical_accuracy: 0.4751 - val_recall: 0.9403 - val_precision: 0.1897\n",
      "Epoch 34/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.7217 - categorical_accuracy: 0.3955 - recall: 0.8992 - precision: 0.1701\n",
      "Epoch 34: val_categorical_accuracy did not improve from 0.47512\n",
      "Model Metric\n",
      "############## F1 score :  0.2859555586343715\n",
      "############## Validation F1 score :  0.3137689971483155\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.7245 - categorical_accuracy: 0.3945 - recall: 0.8994 - precision: 0.1700 - val_loss: 1.5189 - val_categorical_accuracy: 0.4618 - val_recall: 0.9383 - val_precision: 0.1884\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.6918 - categorical_accuracy: 0.4067 - recall: 0.9048 - precision: 0.1731\n",
      "Epoch 35: val_categorical_accuracy improved from 0.47512 to 0.48109, saving model to ./model_save/weights-35-0.4811.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.2905434316643145\n",
      "############## Validation F1 score :  0.32242617902286874\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.6918 - categorical_accuracy: 0.4067 - recall: 0.9048 - precision: 0.1731 - val_loss: 1.4829 - val_categorical_accuracy: 0.4811 - val_recall: 0.9383 - val_precision: 0.1947\n",
      "Epoch 36/100\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 1.6729 - categorical_accuracy: 0.4124 - recall: 0.9039 - precision: 0.1764\n",
      "Epoch 36: val_categorical_accuracy improved from 0.48109 to 0.48772, saving model to ./model_save/weights-36-0.4877.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.29565154998846793\n",
      "############## Validation F1 score :  0.32560808470165997\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.6709 - categorical_accuracy: 0.4108 - recall: 0.9046 - precision: 0.1767 - val_loss: 1.4716 - val_categorical_accuracy: 0.4877 - val_recall: 0.9416 - val_precision: 0.1968\n",
      "Epoch 37/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.6626 - categorical_accuracy: 0.4184 - recall: 0.9033 - precision: 0.1767\n",
      "Epoch 37: val_categorical_accuracy improved from 0.48772 to 0.49768, saving model to ./model_save/weights-37-0.4977.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.29627121796568245\n",
      "############## Validation F1 score :  0.3277623056940648\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 1.6583 - categorical_accuracy: 0.4193 - recall: 0.9042 - precision: 0.1772 - val_loss: 1.4560 - val_categorical_accuracy: 0.4977 - val_recall: 0.9370 - val_precision: 0.1986\n",
      "Epoch 38/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.6467 - categorical_accuracy: 0.4203 - recall: 0.9061 - precision: 0.1793\n",
      "Epoch 38: val_categorical_accuracy did not improve from 0.49768\n",
      "Model Metric\n",
      "############## F1 score :  0.2994623776105426\n",
      "############## Validation F1 score :  0.3263608068781399\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.6483 - categorical_accuracy: 0.4207 - recall: 0.9061 - precision: 0.1794 - val_loss: 1.4658 - val_categorical_accuracy: 0.4811 - val_recall: 0.9370 - val_precision: 0.1976\n",
      "Epoch 39/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.6290 - categorical_accuracy: 0.4249 - recall: 0.9129 - precision: 0.1818\n",
      "Epoch 39: val_categorical_accuracy did not improve from 0.49768\n",
      "Model Metric\n",
      "############## F1 score :  0.3033377450409953\n",
      "############## Validation F1 score :  0.3360986066082259\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.6271 - categorical_accuracy: 0.4258 - recall: 0.9132 - precision: 0.1819 - val_loss: 1.4379 - val_categorical_accuracy: 0.4891 - val_recall: 0.9409 - val_precision: 0.2046\n",
      "Epoch 40/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.6114 - categorical_accuracy: 0.4283 - recall: 0.9095 - precision: 0.1842\n",
      "Epoch 40: val_categorical_accuracy did not improve from 0.49768\n",
      "Model Metric\n",
      "############## F1 score :  0.30665588509049485\n",
      "############## Validation F1 score :  0.33843927891599107\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.6113 - categorical_accuracy: 0.4278 - recall: 0.9101 - precision: 0.1844 - val_loss: 1.4320 - val_categorical_accuracy: 0.4877 - val_recall: 0.9310 - val_precision: 0.2068\n",
      "Epoch 41/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.6030 - categorical_accuracy: 0.4316 - recall: 0.9138 - precision: 0.1855\n",
      "Epoch 41: val_categorical_accuracy improved from 0.49768 to 0.50431, saving model to ./model_save/weights-41-0.5043.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.30845448712221213\n",
      "############## Validation F1 score :  0.33942746552600234\n",
      "53/53 [==============================] - 2s 37ms/step - loss: 1.6029 - categorical_accuracy: 0.4306 - recall: 0.9141 - precision: 0.1855 - val_loss: 1.4162 - val_categorical_accuracy: 0.5043 - val_recall: 0.9363 - val_precision: 0.2073\n",
      "Epoch 42/100\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 1.5804 - categorical_accuracy: 0.4423 - recall: 0.9153 - precision: 0.1883\n",
      "Epoch 42: val_categorical_accuracy did not improve from 0.50431\n",
      "Model Metric\n",
      "############## F1 score :  0.3125251944786517\n",
      "############## Validation F1 score :  0.34993169662248513\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 1.5785 - categorical_accuracy: 0.4426 - recall: 0.9152 - precision: 0.1884 - val_loss: 1.3849 - val_categorical_accuracy: 0.5043 - val_recall: 0.9350 - val_precision: 0.2152\n",
      "Epoch 43/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.5698 - categorical_accuracy: 0.4492 - recall: 0.9166 - precision: 0.1902\n",
      "Epoch 43: val_categorical_accuracy improved from 0.50431 to 0.51228, saving model to ./model_save/weights-43-0.5123.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.31475103040988056\n",
      "############## Validation F1 score :  0.3482856124715341\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.5713 - categorical_accuracy: 0.4489 - recall: 0.9168 - precision: 0.1900 - val_loss: 1.3833 - val_categorical_accuracy: 0.5123 - val_recall: 0.9403 - val_precision: 0.2137\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.5593 - categorical_accuracy: 0.4489 - recall: 0.9183 - precision: 0.1918\n",
      "Epoch 44: val_categorical_accuracy improved from 0.51228 to 0.51360, saving model to ./model_save/weights-44-0.5136.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.31727178323417654\n",
      "############## Validation F1 score :  0.34714390126101247\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.5593 - categorical_accuracy: 0.4489 - recall: 0.9183 - precision: 0.1918 - val_loss: 1.3854 - val_categorical_accuracy: 0.5136 - val_recall: 0.9396 - val_precision: 0.2129\n",
      "Epoch 45/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.5395 - categorical_accuracy: 0.4548 - recall: 0.9180 - precision: 0.1929\n",
      "Epoch 45: val_categorical_accuracy improved from 0.51360 to 0.51758, saving model to ./model_save/weights-45-0.5176.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.31923761895315295\n",
      "############## Validation F1 score :  0.35219813898278307\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.5379 - categorical_accuracy: 0.4541 - recall: 0.9181 - precision: 0.1932 - val_loss: 1.3610 - val_categorical_accuracy: 0.5176 - val_recall: 0.9436 - val_precision: 0.2165\n",
      "Epoch 46/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.5230 - categorical_accuracy: 0.4600 - recall: 0.9186 - precision: 0.1947\n",
      "Epoch 46: val_categorical_accuracy did not improve from 0.51758\n",
      "Model Metric\n",
      "############## F1 score :  0.3214221179599347\n",
      "############## Validation F1 score :  0.3598030512965597\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.5226 - categorical_accuracy: 0.4594 - recall: 0.9184 - precision: 0.1948 - val_loss: 1.3496 - val_categorical_accuracy: 0.5136 - val_recall: 0.9456 - val_precision: 0.2222\n",
      "Epoch 47/100\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 1.5264 - categorical_accuracy: 0.4545 - recall: 0.9182 - precision: 0.1947\n",
      "Epoch 47: val_categorical_accuracy did not improve from 0.51758\n",
      "Model Metric\n",
      "############## F1 score :  0.32150378105121996\n",
      "############## Validation F1 score :  0.3589290199304367\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.5267 - categorical_accuracy: 0.4553 - recall: 0.9180 - precision: 0.1949 - val_loss: 1.3505 - val_categorical_accuracy: 0.5143 - val_recall: 0.9429 - val_precision: 0.2217\n",
      "Epoch 48/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.5054 - categorical_accuracy: 0.4683 - recall: 0.9199 - precision: 0.1959\n",
      "Epoch 48: val_categorical_accuracy improved from 0.51758 to 0.52090, saving model to ./model_save/weights-48-0.5209.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.32350995760616075\n",
      "############## Validation F1 score :  0.36417450301052384\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.5053 - categorical_accuracy: 0.4689 - recall: 0.9196 - precision: 0.1963 - val_loss: 1.3385 - val_categorical_accuracy: 0.5209 - val_recall: 0.9390 - val_precision: 0.2259\n",
      "Epoch 49/100\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 1.4798 - categorical_accuracy: 0.4698 - recall: 0.9215 - precision: 0.2014\n",
      "Epoch 49: val_categorical_accuracy improved from 0.52090 to 0.52422, saving model to ./model_save/weights-49-0.5242.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.3302463434074116\n",
      "############## Validation F1 score :  0.3632872560971865\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.4838 - categorical_accuracy: 0.4686 - recall: 0.9208 - precision: 0.2012 - val_loss: 1.3291 - val_categorical_accuracy: 0.5242 - val_recall: 0.9416 - val_precision: 0.2251\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.4871 - categorical_accuracy: 0.4727 - recall: 0.9222 - precision: 0.2001\n",
      "Epoch 50: val_categorical_accuracy did not improve from 0.52422\n",
      "Model Metric\n",
      "############## F1 score :  0.32884351883101676\n",
      "############## Validation F1 score :  0.3725747278560515\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.4871 - categorical_accuracy: 0.4727 - recall: 0.9222 - precision: 0.2001 - val_loss: 1.3204 - val_categorical_accuracy: 0.5136 - val_recall: 0.9429 - val_precision: 0.2322\n",
      "Epoch 51/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.4763 - categorical_accuracy: 0.4763 - recall: 0.9247 - precision: 0.2018\n",
      "Epoch 51: val_categorical_accuracy did not improve from 0.52422\n",
      "Model Metric\n",
      "############## F1 score :  0.331503414847853\n",
      "############## Validation F1 score :  0.36569027310708935\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.4744 - categorical_accuracy: 0.4764 - recall: 0.9244 - precision: 0.2020 - val_loss: 1.3472 - val_categorical_accuracy: 0.5242 - val_recall: 0.9237 - val_precision: 0.2280\n",
      "Epoch 52/100\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 1.4577 - categorical_accuracy: 0.4793 - recall: 0.9251 - precision: 0.2038\n",
      "Epoch 52: val_categorical_accuracy improved from 0.52422 to 0.52687, saving model to ./model_save/weights-52-0.5269.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.334092995446763\n",
      "############## Validation F1 score :  0.370961405407487\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.4575 - categorical_accuracy: 0.4792 - recall: 0.9247 - precision: 0.2039 - val_loss: 1.3113 - val_categorical_accuracy: 0.5269 - val_recall: 0.9409 - val_precision: 0.2310\n",
      "Epoch 53/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.4476 - categorical_accuracy: 0.4820 - recall: 0.9239 - precision: 0.2056\n",
      "Epoch 53: val_categorical_accuracy improved from 0.52687 to 0.53351, saving model to ./model_save/weights-53-0.5335.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.33699012327910216\n",
      "############## Validation F1 score :  0.37735849183803943\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 1.4436 - categorical_accuracy: 0.4835 - recall: 0.9246 - precision: 0.2060 - val_loss: 1.2953 - val_categorical_accuracy: 0.5335 - val_recall: 0.9356 - val_precision: 0.2363\n",
      "Epoch 54/100\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 1.4313 - categorical_accuracy: 0.4922 - recall: 0.9241 - precision: 0.2089\n",
      "Epoch 54: val_categorical_accuracy did not improve from 0.53351\n",
      "Model Metric\n",
      "############## F1 score :  0.34063691328201984\n",
      "############## Validation F1 score :  0.37833511903202793\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.4321 - categorical_accuracy: 0.4927 - recall: 0.9233 - precision: 0.2088 - val_loss: 1.2952 - val_categorical_accuracy: 0.5315 - val_recall: 0.9409 - val_precision: 0.2368\n",
      "Epoch 55/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.4299 - categorical_accuracy: 0.4940 - recall: 0.9236 - precision: 0.2083\n",
      "Epoch 55: val_categorical_accuracy improved from 0.53351 to 0.53616, saving model to ./model_save/weights-55-0.5362.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.34025448735192976\n",
      "############## Validation F1 score :  0.37673130730961324\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 1.4281 - categorical_accuracy: 0.4938 - recall: 0.9242 - precision: 0.2085 - val_loss: 1.2869 - val_categorical_accuracy: 0.5362 - val_recall: 0.9476 - val_precision: 0.2351\n",
      "Epoch 56/100\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 1.4209 - categorical_accuracy: 0.4955 - recall: 0.9253 - precision: 0.2087\n",
      "Epoch 56: val_categorical_accuracy improved from 0.53616 to 0.54346, saving model to ./model_save/weights-56-0.5435.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.34068260901098174\n",
      "############## Validation F1 score :  0.37731359188215036\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.4206 - categorical_accuracy: 0.4946 - recall: 0.9256 - precision: 0.2088 - val_loss: 1.2763 - val_categorical_accuracy: 0.5435 - val_recall: 0.9469 - val_precision: 0.2356\n",
      "Epoch 57/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.4011 - categorical_accuracy: 0.5078 - recall: 0.9262 - precision: 0.2126\n",
      "Epoch 57: val_categorical_accuracy did not improve from 0.54346\n",
      "Model Metric\n",
      "############## F1 score :  0.3455441154887046\n",
      "############## Validation F1 score :  0.38155248129270086\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.4009 - categorical_accuracy: 0.5066 - recall: 0.9262 - precision: 0.2124 - val_loss: 1.2685 - val_categorical_accuracy: 0.5421 - val_recall: 0.9443 - val_precision: 0.2391\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.3982 - categorical_accuracy: 0.5012 - recall: 0.9287 - precision: 0.2134\n",
      "Epoch 58: val_categorical_accuracy improved from 0.54346 to 0.55342, saving model to ./model_save/weights-58-0.5534.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.3469967197101092\n",
      "############## Validation F1 score :  0.38740588071741383\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.3982 - categorical_accuracy: 0.5012 - recall: 0.9287 - precision: 0.2134 - val_loss: 1.2629 - val_categorical_accuracy: 0.5534 - val_recall: 0.9390 - val_precision: 0.2440\n",
      "Epoch 59/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.3858 - categorical_accuracy: 0.5068 - recall: 0.9291 - precision: 0.2153\n",
      "Epoch 59: val_categorical_accuracy did not improve from 0.55342\n",
      "Model Metric\n",
      "############## F1 score :  0.3492763849823997\n",
      "############## Validation F1 score :  0.38570263415208306\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.3870 - categorical_accuracy: 0.5070 - recall: 0.9285 - precision: 0.2151 - val_loss: 1.2672 - val_categorical_accuracy: 0.5348 - val_recall: 0.9416 - val_precision: 0.2425\n",
      "Epoch 60/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.3764 - categorical_accuracy: 0.5117 - recall: 0.9288 - precision: 0.2159\n",
      "Epoch 60: val_categorical_accuracy improved from 0.55342 to 0.55408, saving model to ./model_save/weights-60-0.5541.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.3501133606811404\n",
      "############## Validation F1 score :  0.38752722724789657\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 1.3781 - categorical_accuracy: 0.5115 - recall: 0.9284 - precision: 0.2157 - val_loss: 1.2445 - val_categorical_accuracy: 0.5541 - val_recall: 0.9443 - val_precision: 0.2438\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.3687 - categorical_accuracy: 0.5141 - recall: 0.9320 - precision: 0.2179\n",
      "Epoch 61: val_categorical_accuracy did not improve from 0.55408\n",
      "Model Metric\n",
      "############## F1 score :  0.3531977395634217\n",
      "############## Validation F1 score :  0.38481425734606073\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.3687 - categorical_accuracy: 0.5141 - recall: 0.9320 - precision: 0.2179 - val_loss: 1.2522 - val_categorical_accuracy: 0.5508 - val_recall: 0.9383 - val_precision: 0.2420\n",
      "Epoch 62/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.3586 - categorical_accuracy: 0.5146 - recall: 0.9335 - precision: 0.2203\n",
      "Epoch 62: val_categorical_accuracy did not improve from 0.55408\n",
      "Model Metric\n",
      "############## F1 score :  0.3562870462470513\n",
      "############## Validation F1 score :  0.39110744570095723\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.3597 - categorical_accuracy: 0.5149 - recall: 0.9335 - precision: 0.2202 - val_loss: 1.2385 - val_categorical_accuracy: 0.5514 - val_recall: 0.9456 - val_precision: 0.2465\n",
      "Epoch 63/100\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 1.3454 - categorical_accuracy: 0.5211 - recall: 0.9327 - precision: 0.2210\n",
      "Epoch 63: val_categorical_accuracy improved from 0.55408 to 0.55740, saving model to ./model_save/weights-63-0.5574.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.35724988760970616\n",
      "############## Validation F1 score :  0.3910131222973841\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.3445 - categorical_accuracy: 0.5207 - recall: 0.9323 - precision: 0.2210 - val_loss: 1.2383 - val_categorical_accuracy: 0.5574 - val_recall: 0.9297 - val_precision: 0.2476\n",
      "Epoch 64/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.3360 - categorical_accuracy: 0.5275 - recall: 0.9311 - precision: 0.2242\n",
      "Epoch 64: val_categorical_accuracy improved from 0.55740 to 0.56271, saving model to ./model_save/weights-64-0.5627.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.3614137055511116\n",
      "############## Validation F1 score :  0.39282236329223197\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 1.3358 - categorical_accuracy: 0.5274 - recall: 0.9313 - precision: 0.2242 - val_loss: 1.2346 - val_categorical_accuracy: 0.5627 - val_recall: 0.9370 - val_precision: 0.2485\n",
      "Epoch 65/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.3201 - categorical_accuracy: 0.5319 - recall: 0.9314 - precision: 0.2250\n",
      "Epoch 65: val_categorical_accuracy improved from 0.56271 to 0.56603, saving model to ./model_save/weights-65-0.5660.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.36223749562311447\n",
      "############## Validation F1 score :  0.3959983446240782\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.3213 - categorical_accuracy: 0.5317 - recall: 0.9309 - precision: 0.2249 - val_loss: 1.2175 - val_categorical_accuracy: 0.5660 - val_recall: 0.9456 - val_precision: 0.2504\n",
      "Epoch 66/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.3247 - categorical_accuracy: 0.5309 - recall: 0.9329 - precision: 0.2251\n",
      "Epoch 66: val_categorical_accuracy did not improve from 0.56603\n",
      "Model Metric\n",
      "############## F1 score :  0.36257813395818755\n",
      "############## Validation F1 score :  0.396078416111642\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.3252 - categorical_accuracy: 0.5299 - recall: 0.9329 - precision: 0.2250 - val_loss: 1.2197 - val_categorical_accuracy: 0.5567 - val_recall: 0.9383 - val_precision: 0.2510\n",
      "Epoch 67/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.3260 - categorical_accuracy: 0.5264 - recall: 0.9310 - precision: 0.2242\n",
      "Epoch 67: val_categorical_accuracy improved from 0.56603 to 0.57731, saving model to ./model_save/weights-67-0.5773.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.36099626173040855\n",
      "############## Validation F1 score :  0.3948138867414989\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.3295 - categorical_accuracy: 0.5250 - recall: 0.9308 - precision: 0.2239 - val_loss: 1.2189 - val_categorical_accuracy: 0.5773 - val_recall: 0.9396 - val_precision: 0.2499\n",
      "Epoch 68/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.3080 - categorical_accuracy: 0.5394 - recall: 0.9323 - precision: 0.2278\n",
      "Epoch 68: val_categorical_accuracy improved from 0.57731 to 0.58195, saving model to ./model_save/weights-68-0.5820.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.36624941602761607\n",
      "############## Validation F1 score :  0.389285714524789\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.3067 - categorical_accuracy: 0.5399 - recall: 0.9325 - precision: 0.2279 - val_loss: 1.2081 - val_categorical_accuracy: 0.5820 - val_recall: 0.9403 - val_precision: 0.2455\n",
      "Epoch 69/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.2908 - categorical_accuracy: 0.5378 - recall: 0.9350 - precision: 0.2296\n",
      "Epoch 69: val_categorical_accuracy did not improve from 0.58195\n",
      "Model Metric\n",
      "############## F1 score :  0.36862471404246494\n",
      "############## Validation F1 score :  0.40078973985162347\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.2897 - categorical_accuracy: 0.5383 - recall: 0.9347 - precision: 0.2296 - val_loss: 1.1921 - val_categorical_accuracy: 0.5713 - val_recall: 0.9429 - val_precision: 0.2545\n",
      "Epoch 70/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.2812 - categorical_accuracy: 0.5463 - recall: 0.9361 - precision: 0.2314\n",
      "Epoch 70: val_categorical_accuracy did not improve from 0.58195\n",
      "Model Metric\n",
      "############## F1 score :  0.3711071787832266\n",
      "############## Validation F1 score :  0.4043403898464274\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.2817 - categorical_accuracy: 0.5458 - recall: 0.9358 - precision: 0.2314 - val_loss: 1.1918 - val_categorical_accuracy: 0.5674 - val_recall: 0.9396 - val_precision: 0.2576\n",
      "Epoch 71/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.2860 - categorical_accuracy: 0.5404 - recall: 0.9358 - precision: 0.2305\n",
      "Epoch 71: val_categorical_accuracy did not improve from 0.58195\n",
      "Model Metric\n",
      "############## F1 score :  0.37070576466326244\n",
      "############## Validation F1 score :  0.40854625741912753\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 1.2830 - categorical_accuracy: 0.5411 - recall: 0.9362 - precision: 0.2311 - val_loss: 1.1874 - val_categorical_accuracy: 0.5747 - val_recall: 0.9390 - val_precision: 0.2611\n",
      "Epoch 72/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.2823 - categorical_accuracy: 0.5412 - recall: 0.9364 - precision: 0.2317\n",
      "Epoch 72: val_categorical_accuracy did not improve from 0.58195\n",
      "Model Metric\n",
      "############## F1 score :  0.3717721567948138\n",
      "############## Validation F1 score :  0.40726329937554273\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.2817 - categorical_accuracy: 0.5414 - recall: 0.9363 - precision: 0.2319 - val_loss: 1.1850 - val_categorical_accuracy: 0.5773 - val_recall: 0.9376 - val_precision: 0.2601\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.2584 - categorical_accuracy: 0.5554 - recall: 0.9383 - precision: 0.2365\n",
      "Epoch 73: val_categorical_accuracy improved from 0.58195 to 0.58859, saving model to ./model_save/weights-73-0.5886.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.3778107738733641\n",
      "############## Validation F1 score :  0.4079573452233105\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.2584 - categorical_accuracy: 0.5554 - recall: 0.9383 - precision: 0.2365 - val_loss: 1.1794 - val_categorical_accuracy: 0.5886 - val_recall: 0.9390 - val_precision: 0.2606\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.2692 - categorical_accuracy: 0.5504 - recall: 0.9362 - precision: 0.2344\n",
      "Epoch 74: val_categorical_accuracy did not improve from 0.58859\n",
      "Model Metric\n",
      "############## F1 score :  0.37498891791146205\n",
      "############## Validation F1 score :  0.4087359130699972\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.2692 - categorical_accuracy: 0.5504 - recall: 0.9362 - precision: 0.2344 - val_loss: 1.1734 - val_categorical_accuracy: 0.5886 - val_recall: 0.9376 - val_precision: 0.2613\n",
      "Epoch 75/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.2522 - categorical_accuracy: 0.5559 - recall: 0.9367 - precision: 0.2361\n",
      "Epoch 75: val_categorical_accuracy did not improve from 0.58859\n",
      "Model Metric\n",
      "############## F1 score :  0.3771903836876163\n",
      "############## Validation F1 score :  0.40507771904950435\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.2519 - categorical_accuracy: 0.5552 - recall: 0.9369 - precision: 0.2361 - val_loss: 1.1708 - val_categorical_accuracy: 0.5839 - val_recall: 0.9423 - val_precision: 0.2580\n",
      "Epoch 76/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.2324 - categorical_accuracy: 0.5600 - recall: 0.9395 - precision: 0.2403\n",
      "Epoch 76: val_categorical_accuracy improved from 0.58859 to 0.59058, saving model to ./model_save/weights-76-0.5906.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.38279008046549284\n",
      "############## Validation F1 score :  0.41212296977631885\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.2330 - categorical_accuracy: 0.5598 - recall: 0.9396 - precision: 0.2404 - val_loss: 1.1559 - val_categorical_accuracy: 0.5906 - val_recall: 0.9429 - val_precision: 0.2637\n",
      "Epoch 77/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.2388 - categorical_accuracy: 0.5627 - recall: 0.9358 - precision: 0.2394\n",
      "Epoch 77: val_categorical_accuracy improved from 0.59058 to 0.59522, saving model to ./model_save/weights-77-0.5952.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.3813215578928992\n",
      "############## Validation F1 score :  0.4069934134311637\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.2394 - categorical_accuracy: 0.5623 - recall: 0.9362 - precision: 0.2394 - val_loss: 1.1573 - val_categorical_accuracy: 0.5952 - val_recall: 0.9423 - val_precision: 0.2596\n",
      "Epoch 78/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.2284 - categorical_accuracy: 0.5648 - recall: 0.9396 - precision: 0.2406\n",
      "Epoch 78: val_categorical_accuracy did not improve from 0.59522\n",
      "Model Metric\n",
      "############## F1 score :  0.3831374947803908\n",
      "############## Validation F1 score :  0.41688809111860914\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.2293 - categorical_accuracy: 0.5645 - recall: 0.9394 - precision: 0.2406 - val_loss: 1.1527 - val_categorical_accuracy: 0.5952 - val_recall: 0.9370 - val_precision: 0.2681\n",
      "Epoch 79/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.2290 - categorical_accuracy: 0.5601 - recall: 0.9419 - precision: 0.2420\n",
      "Epoch 79: val_categorical_accuracy did not improve from 0.59522\n",
      "Model Metric\n",
      "############## F1 score :  0.3851802734972636\n",
      "############## Validation F1 score :  0.4193021679908637\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.2280 - categorical_accuracy: 0.5600 - recall: 0.9422 - precision: 0.2421 - val_loss: 1.1512 - val_categorical_accuracy: 0.5853 - val_recall: 0.9370 - val_precision: 0.2701\n",
      "Epoch 80/100\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 1.2158 - categorical_accuracy: 0.5637 - recall: 0.9397 - precision: 0.2429\n",
      "Epoch 80: val_categorical_accuracy improved from 0.59522 to 0.59589, saving model to ./model_save/weights-80-0.5959.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.38612870856703835\n",
      "############## Validation F1 score :  0.4220128629461002\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.2148 - categorical_accuracy: 0.5653 - recall: 0.9397 - precision: 0.2430 - val_loss: 1.1453 - val_categorical_accuracy: 0.5959 - val_recall: 0.9363 - val_precision: 0.2724\n",
      "Epoch 81/100\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 1.2144 - categorical_accuracy: 0.5690 - recall: 0.9383 - precision: 0.2449\n",
      "Epoch 81: val_categorical_accuracy did not improve from 0.59589\n",
      "Model Metric\n",
      "############## F1 score :  0.38771464342496414\n",
      "############## Validation F1 score :  0.40925421883938473\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.2188 - categorical_accuracy: 0.5687 - recall: 0.9378 - precision: 0.2444 - val_loss: 1.1513 - val_categorical_accuracy: 0.5952 - val_recall: 0.9449 - val_precision: 0.2612\n",
      "Epoch 82/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1989 - categorical_accuracy: 0.5757 - recall: 0.9391 - precision: 0.2471\n",
      "Epoch 82: val_categorical_accuracy improved from 0.59589 to 0.59655, saving model to ./model_save/weights-82-0.5965.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.39124554876858975\n",
      "############## Validation F1 score :  0.41980434270138295\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.1995 - categorical_accuracy: 0.5754 - recall: 0.9390 - precision: 0.2471 - val_loss: 1.1412 - val_categorical_accuracy: 0.5965 - val_recall: 0.9396 - val_precision: 0.2703\n",
      "Epoch 83/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1925 - categorical_accuracy: 0.5724 - recall: 0.9400 - precision: 0.2464\n",
      "Epoch 83: val_categorical_accuracy improved from 0.59655 to 0.59854, saving model to ./model_save/weights-83-0.5985.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.39039857587095345\n",
      "############## Validation F1 score :  0.42706582375099755\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.1931 - categorical_accuracy: 0.5723 - recall: 0.9401 - precision: 0.2464 - val_loss: 1.1437 - val_categorical_accuracy: 0.5985 - val_recall: 0.9277 - val_precision: 0.2774\n",
      "Epoch 84/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1876 - categorical_accuracy: 0.5750 - recall: 0.9407 - precision: 0.2494\n",
      "Epoch 84: val_categorical_accuracy did not improve from 0.59854\n",
      "Model Metric\n",
      "############## F1 score :  0.394053192673634\n",
      "############## Validation F1 score :  0.41436705297417625\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1904 - categorical_accuracy: 0.5738 - recall: 0.9405 - precision: 0.2492 - val_loss: 1.1430 - val_categorical_accuracy: 0.5893 - val_recall: 0.9416 - val_precision: 0.2656\n",
      "Epoch 85/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1899 - categorical_accuracy: 0.5790 - recall: 0.9399 - precision: 0.2477\n",
      "Epoch 85: val_categorical_accuracy improved from 0.59854 to 0.59920, saving model to ./model_save/weights-85-0.5992.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.39217437617279166\n",
      "############## Validation F1 score :  0.4253202909316541\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.1888 - categorical_accuracy: 0.5787 - recall: 0.9398 - precision: 0.2478 - val_loss: 1.1341 - val_categorical_accuracy: 0.5992 - val_recall: 0.9363 - val_precision: 0.2752\n",
      "Epoch 86/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1795 - categorical_accuracy: 0.5775 - recall: 0.9421 - precision: 0.2491\n",
      "Epoch 86: val_categorical_accuracy did not improve from 0.59920\n",
      "Model Metric\n",
      "############## F1 score :  0.394231811097595\n",
      "############## Validation F1 score :  0.42558983585087895\n",
      "53/53 [==============================] - 3s 62ms/step - loss: 1.1780 - categorical_accuracy: 0.5787 - recall: 0.9419 - precision: 0.2493 - val_loss: 1.1405 - val_categorical_accuracy: 0.5965 - val_recall: 0.9336 - val_precision: 0.2756\n",
      "Epoch 87/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1730 - categorical_accuracy: 0.5798 - recall: 0.9433 - precision: 0.2532\n",
      "Epoch 87: val_categorical_accuracy did not improve from 0.59920\n",
      "Model Metric\n",
      "############## F1 score :  0.39933812579457856\n",
      "############## Validation F1 score :  0.429438535056608\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.1719 - categorical_accuracy: 0.5796 - recall: 0.9436 - precision: 0.2533 - val_loss: 1.1358 - val_categorical_accuracy: 0.5972 - val_recall: 0.9390 - val_precision: 0.2784\n",
      "Epoch 88/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1569 - categorical_accuracy: 0.5836 - recall: 0.9419 - precision: 0.2527\n",
      "Epoch 88: val_categorical_accuracy improved from 0.59920 to 0.61115, saving model to ./model_save/weights-88-0.6111.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.3985892751294364\n",
      "############## Validation F1 score :  0.4341922404079514\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.1558 - categorical_accuracy: 0.5838 - recall: 0.9422 - precision: 0.2528 - val_loss: 1.1282 - val_categorical_accuracy: 0.6111 - val_recall: 0.9336 - val_precision: 0.2829\n",
      "Epoch 89/100\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 1.1631 - categorical_accuracy: 0.5805 - recall: 0.9414 - precision: 0.2548\n",
      "Epoch 89: val_categorical_accuracy did not improve from 0.61115\n",
      "Model Metric\n",
      "############## F1 score :  0.4005585069364815\n",
      "############## Validation F1 score :  0.43101865280115736\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.1636 - categorical_accuracy: 0.5801 - recall: 0.9418 - precision: 0.2544 - val_loss: 1.1254 - val_categorical_accuracy: 0.5999 - val_recall: 0.9350 - val_precision: 0.2801\n",
      "Epoch 90/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1549 - categorical_accuracy: 0.5912 - recall: 0.9441 - precision: 0.2538\n",
      "Epoch 90: val_categorical_accuracy improved from 0.61115 to 0.61181, saving model to ./model_save/weights-90-0.6118.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.40056336997651903\n",
      "############## Validation F1 score :  0.4346213418137652\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.1539 - categorical_accuracy: 0.5909 - recall: 0.9442 - precision: 0.2542 - val_loss: 1.1234 - val_categorical_accuracy: 0.6118 - val_recall: 0.9330 - val_precision: 0.2833\n",
      "Epoch 91/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1538 - categorical_accuracy: 0.5828 - recall: 0.9439 - precision: 0.2552\n",
      "Epoch 91: val_categorical_accuracy did not improve from 0.61181\n",
      "Model Metric\n",
      "############## F1 score :  0.40127978308468737\n",
      "############## Validation F1 score :  0.4320097971080631\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.1558 - categorical_accuracy: 0.5830 - recall: 0.9438 - precision: 0.2548 - val_loss: 1.1224 - val_categorical_accuracy: 0.6072 - val_recall: 0.9350 - val_precision: 0.2809\n",
      "Epoch 92/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1478 - categorical_accuracy: 0.5895 - recall: 0.9450 - precision: 0.2558\n",
      "Epoch 92: val_categorical_accuracy did not improve from 0.61181\n",
      "Model Metric\n",
      "############## F1 score :  0.40240163256128575\n",
      "############## Validation F1 score :  0.43020945532922544\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.1491 - categorical_accuracy: 0.5892 - recall: 0.9444 - precision: 0.2557 - val_loss: 1.1218 - val_categorical_accuracy: 0.6005 - val_recall: 0.9336 - val_precision: 0.2795\n",
      "Epoch 93/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1654 - categorical_accuracy: 0.5780 - recall: 0.9439 - precision: 0.2539\n",
      "Epoch 93: val_categorical_accuracy improved from 0.61181 to 0.61314, saving model to ./model_save/weights-93-0.6131.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.4005882565609868\n",
      "############## Validation F1 score :  0.4369173215978881\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.1625 - categorical_accuracy: 0.5793 - recall: 0.9444 - precision: 0.2542 - val_loss: 1.1287 - val_categorical_accuracy: 0.6131 - val_recall: 0.9330 - val_precision: 0.2853\n",
      "Epoch 94/100\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 1.1494 - categorical_accuracy: 0.5828 - recall: 0.9433 - precision: 0.2561\n",
      "Epoch 94: val_categorical_accuracy did not improve from 0.61314\n",
      "Model Metric\n",
      "############## F1 score :  0.4026558411058831\n",
      "############## Validation F1 score :  0.42811693324476957\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1478 - categorical_accuracy: 0.5840 - recall: 0.9440 - precision: 0.2559 - val_loss: 1.1184 - val_categorical_accuracy: 0.6052 - val_recall: 0.9376 - val_precision: 0.2774\n",
      "Epoch 95/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1425 - categorical_accuracy: 0.5902 - recall: 0.9432 - precision: 0.2569\n",
      "Epoch 95: val_categorical_accuracy did not improve from 0.61314\n",
      "Model Metric\n",
      "############## F1 score :  0.4036511591295198\n",
      "############## Validation F1 score :  0.4394506853967265\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.1430 - categorical_accuracy: 0.5899 - recall: 0.9428 - precision: 0.2568 - val_loss: 1.1018 - val_categorical_accuracy: 0.6125 - val_recall: 0.9343 - val_precision: 0.2873\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.1257 - categorical_accuracy: 0.5878 - recall: 0.9475 - precision: 0.2607\n",
      "Epoch 96: val_categorical_accuracy improved from 0.61314 to 0.61712, saving model to ./model_save/weights-96-0.6171.hdf5\n",
      "Model Metric\n",
      "############## F1 score :  0.4088499715319481\n",
      "############## Validation F1 score :  0.43682087042553486\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 1.1257 - categorical_accuracy: 0.5878 - recall: 0.9475 - precision: 0.2607 - val_loss: 1.1008 - val_categorical_accuracy: 0.6171 - val_recall: 0.9336 - val_precision: 0.2851\n",
      "Epoch 97/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1234 - categorical_accuracy: 0.5915 - recall: 0.9472 - precision: 0.2605\n",
      "Epoch 97: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.40885632161026775\n",
      "############## Validation F1 score :  0.44096950581646743\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.1223 - categorical_accuracy: 0.5919 - recall: 0.9468 - precision: 0.2607 - val_loss: 1.1130 - val_categorical_accuracy: 0.6078 - val_recall: 0.9356 - val_precision: 0.2885\n",
      "Epoch 98/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1362 - categorical_accuracy: 0.5923 - recall: 0.9437 - precision: 0.2595\n",
      "Epoch 98: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.4068713152591189\n",
      "############## Validation F1 score :  0.43932988295648984\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.1338 - categorical_accuracy: 0.5931 - recall: 0.9436 - precision: 0.2594 - val_loss: 1.1081 - val_categorical_accuracy: 0.6065 - val_recall: 0.9310 - val_precision: 0.2875\n",
      "Epoch 99/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1234 - categorical_accuracy: 0.5956 - recall: 0.9455 - precision: 0.2606\n",
      "Epoch 99: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.4083505806410086\n",
      "############## Validation F1 score :  0.4378311201015558\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.1244 - categorical_accuracy: 0.5954 - recall: 0.9452 - precision: 0.2604 - val_loss: 1.1040 - val_categorical_accuracy: 0.6165 - val_recall: 0.9323 - val_precision: 0.2861\n",
      "Epoch 100/100\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 1.1215 - categorical_accuracy: 0.5983 - recall: 0.9475 - precision: 0.2604\n",
      "Epoch 100: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.40789556596129456\n",
      "############## Validation F1 score :  0.4393226618311829\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1216 - categorical_accuracy: 0.5990 - recall: 0.9475 - precision: 0.2599 - val_loss: 1.1038 - val_categorical_accuracy: 0.6125 - val_recall: 0.9297 - val_precision: 0.2876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1513f2d51220>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=100,validation_data=(X_cv,y_cv), batch_size=256,callbacks = all_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e25d2ac3-175f-49c5-8f35-4f40269ae600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload started and will continue reading any new data as it's added to the logdir.\n",
      "\n",
      "To stop uploading, press Ctrl-C.\n",
      "\n",
      "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/ASqnf7bhR7S8uYb9tA5hJg/\n",
      "\n",
      "\u001b[1m[2022-10-17T02:09:39]\u001b[0m Started scanning logdir.\n",
      "\u001b[1m[2022-10-17T02:09:45]\u001b[0m Total uploaded: 1200 scalars, 1900 tensors (1.3 MB), 1 binary objects (119.8 kB)\n",
      "^C2K\u001b[33mListening for new data in logdir...\u001b[0m\n",
      "\n",
      "\n",
      "Interrupted. View your TensorBoard at https://tensorboard.dev/experiment/ASqnf7bhR7S8uYb9tA5hJg/\n"
     ]
    }
   ],
   "source": [
    "!tensorboard dev upload --logdir logs --name Model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8b24fec-61c0-4743-86b9-a0db88f50328",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5059a181-a7b6-4a1c-8b76-3f97997e86d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tokenizer.word_index\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c9d9f9f-cdda-47ef-9e9d-1da438f18714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18828, 3129)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X = tokenizer.texts_to_sequences(X)\n",
    "padded_data_c = tf.keras.preprocessing.sequence.pad_sequences(data_X, padding='post')\n",
    "padded_data_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03268b77-501f-490e-931b-4bca26bdb83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(padded_data_c,y_final,stratify=y_final,test_size=0.2)\n",
    "X_train,X_cv,y_train,y_cv = train_test_split(X_train,y_train,stratify=y_train,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2182f58a-f9ee-444c-be01-ceda8ffb7835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13555, 3129), (3766, 3129), (13555, 20), (3766, 20))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30a7db3b-34fa-4e62-b358-33865c146a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94it [00:00, 6070.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. 94  char loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def loadGloveModel(gloveFile):\n",
    "    print (\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r', encoding=\"utf8\")\n",
    "    model = {}\n",
    "    for line in tqdm(f):\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print (\"Done.\",len(model),\" char loaded!\")\n",
    "    return model\n",
    "glove_emb = loadGloveModel('glove.840B.300d-char.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3c3a5af-cc93-499f-b1c7-fe98a70cf121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size:  43 Vector dims:  300 Sequence Length :  3129\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(a)+1\n",
    "dims = glove_emb['t'].shape[0]\n",
    "seq_length = padded_data_c.shape[1]\n",
    "print(\"Vocab Size: \", vocab_size , \"Vector dims: \", dims , \"Sequence Length : \",seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16780239-bd39-482f-989d-c6d274bcd498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words found and there ratio :  42 0.9767441860465116\n"
     ]
    }
   ],
   "source": [
    "embeding = np.zeros((vocab_size,dims))\n",
    "count = 1\n",
    "not_found = [] \n",
    "for word,idx in a.items():\n",
    "    if glove_emb.get(word) is not None:\n",
    "        count+=1\n",
    "        embeding[idx] = glove_emb[word]\n",
    "    else:\n",
    "        not_found.append(word)\n",
    "print(\"Words found and there ratio : \",count,count/vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cff6be5b-19f9-4b9d-9366-bcee7f1c0f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 300)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65ecaa9-40cb-435d-9731-429047fe61c8",
   "metadata": {},
   "source": [
    "# Model Charatere level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e3b0c2d-3bf8-44a4-a223-de28c0fad9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_input_seq =  tf.keras.layers.Input(shape=(padded_data_c.shape[1],))\n",
    "c_embbeding_layer = tf.keras.layers.Embedding(input_dim=vocab_size,output_dim = dims,weights=[embeding],input_length=seq_length, trainable=False)(c_input_seq)\n",
    "\n",
    "c_layer_1 = tf.keras.layers.Conv1D(filters = 10, kernel_size = 20, strides=5, activation='relu')(c_embbeding_layer)\n",
    "c_layer_2 = tf.keras.layers.Conv1D(filters = 10, kernel_size = 5, strides=1, activation='relu')(c_layer_1)\n",
    "c_max_pool_layer_1 = tf.keras.layers.MaxPool1D( pool_size=4,strides=1)(c_layer_2)\n",
    "\n",
    "c_layer_3 = tf.keras.layers.Conv1D(filters = 10, kernel_size = 3, strides=1, activation='relu')(c_max_pool_layer_1)\n",
    "c_layer_4 = tf.keras.layers.Conv1D(filters = 10, kernel_size = 4, strides=1, activation='relu')(c_layer_3)\n",
    "c_max_pool_layer_2 = tf.keras.layers.MaxPool1D( pool_size=4,strides=1)(c_layer_4)\n",
    "\n",
    "c_flat_layer = tf.keras.layers.Flatten()(c_max_pool_layer_2)\n",
    "c_dropout_layer = tf.keras.layers.Dropout(.5)(c_flat_layer)\n",
    "c_dense_layer_1 = tf.keras.layers.Dense(32,activation='relu')(c_dropout_layer)\n",
    "c_output_layer = tf.keras.layers.Dense(20,activation='softmax')(c_dense_layer_1)\n",
    "\n",
    "char_model = tf.keras.Model(c_input_seq,c_output_layer)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01,momentum=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a66013ef-dc8e-4e52-95de-9e3492547c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_model.compile(optimizer=optimizer, loss='categorical_crossentropy',metrics=['categorical_accuracy',tf.keras.metrics.Recall(thresholds=0.05,name='recall'),tf.keras.metrics.Precision(thresholds=0.05,name='precision')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3cad0948-9237-4f77-a5f0-eedccd4272da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 3129)]            0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 3129, 300)         12900     \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 622, 10)           60010     \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 618, 10)           510       \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 615, 10)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 613, 10)           310       \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 610, 10)           410       \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 607, 10)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6070)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 6070)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                194272    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 20)                660       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 269,072\n",
      "Trainable params: 256,172\n",
      "Non-trainable params: 12,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "char_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c2f586ff-b203-4295-adf9-d1319e2e59ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9960 - categorical_accuracy: 0.0556 - recall: 0.5242 - precision: 0.0522\n",
      "Epoch 1: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.09493649675685036\n",
      "############## Validation F1 score :  0.09845847657557018\n",
      "53/53 [==============================] - 3s 45ms/step - loss: 2.9960 - categorical_accuracy: 0.0556 - recall: 0.5242 - precision: 0.0522 - val_loss: 2.9945 - val_categorical_accuracy: 0.0557 - val_recall: 0.5912 - val_precision: 0.0537\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9941 - categorical_accuracy: 0.0525 - recall: 0.5617 - precision: 0.0528\n",
      "Epoch 2: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.09660352293865078\n",
      "############## Validation F1 score :  0.0995779677069236\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 2.9941 - categorical_accuracy: 0.0525 - recall: 0.5617 - precision: 0.0528 - val_loss: 2.9927 - val_categorical_accuracy: 0.0591 - val_recall: 0.6184 - val_precision: 0.0541\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9919 - categorical_accuracy: 0.0544 - recall: 0.5785 - precision: 0.0531\n",
      "Epoch 3: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.0973033997817804\n",
      "############## Validation F1 score :  0.09929894142825192\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 2.9919 - categorical_accuracy: 0.0544 - recall: 0.5785 - precision: 0.0531 - val_loss: 2.9899 - val_categorical_accuracy: 0.0604 - val_recall: 0.6297 - val_precision: 0.0539\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9886 - categorical_accuracy: 0.0530 - recall: 0.5856 - precision: 0.0535\n",
      "Epoch 4: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.09801936311848708\n",
      "############## Validation F1 score :  0.10132067878673831\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9886 - categorical_accuracy: 0.0530 - recall: 0.5856 - precision: 0.0535 - val_loss: 2.9858 - val_categorical_accuracy: 0.0604 - val_recall: 0.6516 - val_precision: 0.0549\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9851 - categorical_accuracy: 0.0562 - recall: 0.6058 - precision: 0.0549\n",
      "Epoch 5: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.10066015695642211\n",
      "############## Validation F1 score :  0.10356518956514768\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9851 - categorical_accuracy: 0.0562 - recall: 0.6058 - precision: 0.0549 - val_loss: 2.9814 - val_categorical_accuracy: 0.0624 - val_recall: 0.6689 - val_precision: 0.0561\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9813 - categorical_accuracy: 0.0581 - recall: 0.6150 - precision: 0.0557\n",
      "Epoch 6: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.10206780020915165\n",
      "############## Validation F1 score :  0.10661784235619998\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 2.9813 - categorical_accuracy: 0.0581 - recall: 0.6150 - precision: 0.0557 - val_loss: 2.9763 - val_categorical_accuracy: 0.0604 - val_recall: 0.6762 - val_precision: 0.0579\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9764 - categorical_accuracy: 0.0567 - recall: 0.6269 - precision: 0.0572\n",
      "Epoch 7: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.10481264659314744\n",
      "############## Validation F1 score :  0.10850176579344771\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9764 - categorical_accuracy: 0.0567 - recall: 0.6269 - precision: 0.0572 - val_loss: 2.9702 - val_categorical_accuracy: 0.0650 - val_recall: 0.6821 - val_precision: 0.0589\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9718 - categorical_accuracy: 0.0594 - recall: 0.6321 - precision: 0.0580\n",
      "Epoch 8: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.10619206055802137\n",
      "############## Validation F1 score :  0.1085632558923839\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9718 - categorical_accuracy: 0.0594 - recall: 0.6321 - precision: 0.0580 - val_loss: 2.9638 - val_categorical_accuracy: 0.0710 - val_recall: 0.6802 - val_precision: 0.0590\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9656 - categorical_accuracy: 0.0713 - recall: 0.6265 - precision: 0.0582\n",
      "Epoch 9: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.10642270951907488\n",
      "############## Validation F1 score :  0.10831394123251184\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 2.9656 - categorical_accuracy: 0.0713 - recall: 0.6265 - precision: 0.0582 - val_loss: 2.9575 - val_categorical_accuracy: 0.0690 - val_recall: 0.6795 - val_precision: 0.0588\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9604 - categorical_accuracy: 0.0741 - recall: 0.6377 - precision: 0.0588\n",
      "Epoch 10: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.10766576585684114\n",
      "############## Validation F1 score :  0.10923166685535832\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 2.9604 - categorical_accuracy: 0.0741 - recall: 0.6377 - precision: 0.0588 - val_loss: 2.9532 - val_categorical_accuracy: 0.0697 - val_recall: 0.6835 - val_precision: 0.0594\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9557 - categorical_accuracy: 0.0733 - recall: 0.6427 - precision: 0.0593\n",
      "Epoch 11: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.10850396293414895\n",
      "############## Validation F1 score :  0.10995972895320776\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9557 - categorical_accuracy: 0.0733 - recall: 0.6427 - precision: 0.0593 - val_loss: 2.9503 - val_categorical_accuracy: 0.0770 - val_recall: 0.6795 - val_precision: 0.0598\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9519 - categorical_accuracy: 0.0812 - recall: 0.6427 - precision: 0.0598\n",
      "Epoch 12: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.10935793756950685\n",
      "############## Validation F1 score :  0.1105882350380007\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9519 - categorical_accuracy: 0.0812 - recall: 0.6427 - precision: 0.0598 - val_loss: 2.9473 - val_categorical_accuracy: 0.0657 - val_recall: 0.6861 - val_precision: 0.0601\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9484 - categorical_accuracy: 0.0796 - recall: 0.6499 - precision: 0.0602\n",
      "Epoch 13: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.11012901776342769\n",
      "############## Validation F1 score :  0.11135737166898028\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9484 - categorical_accuracy: 0.0796 - recall: 0.6499 - precision: 0.0602 - val_loss: 2.9441 - val_categorical_accuracy: 0.0803 - val_recall: 0.6835 - val_precision: 0.0606\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9445 - categorical_accuracy: 0.0831 - recall: 0.6547 - precision: 0.0612\n",
      "Epoch 14: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.11196124580491158\n",
      "############## Validation F1 score :  0.11208598099039342\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 2.9445 - categorical_accuracy: 0.0831 - recall: 0.6547 - precision: 0.0612 - val_loss: 2.9406 - val_categorical_accuracy: 0.0836 - val_recall: 0.6782 - val_precision: 0.0611\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9434 - categorical_accuracy: 0.0828 - recall: 0.6443 - precision: 0.0610\n",
      "Epoch 15: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.11139243830640634\n",
      "############## Validation F1 score :  0.11295791856504268\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9434 - categorical_accuracy: 0.0828 - recall: 0.6443 - precision: 0.0610 - val_loss: 2.9382 - val_categorical_accuracy: 0.0836 - val_recall: 0.6742 - val_precision: 0.0616\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9399 - categorical_accuracy: 0.0859 - recall: 0.6475 - precision: 0.0617\n",
      "Epoch 16: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.11270336499337377\n",
      "############## Validation F1 score :  0.1136887050298945\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9399 - categorical_accuracy: 0.0859 - recall: 0.6475 - precision: 0.0617 - val_loss: 2.9361 - val_categorical_accuracy: 0.0770 - val_recall: 0.6715 - val_precision: 0.0621\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9366 - categorical_accuracy: 0.0847 - recall: 0.6477 - precision: 0.0621\n",
      "Epoch 17: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.1133264035262928\n",
      "############## Validation F1 score :  0.11418336483588605\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9366 - categorical_accuracy: 0.0847 - recall: 0.6477 - precision: 0.0621 - val_loss: 2.9340 - val_categorical_accuracy: 0.0836 - val_recall: 0.6768 - val_precision: 0.0624\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9345 - categorical_accuracy: 0.0852 - recall: 0.6488 - precision: 0.0627\n",
      "Epoch 18: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.11436002915818014\n",
      "############## Validation F1 score :  0.11445952179330475\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9345 - categorical_accuracy: 0.0852 - recall: 0.6488 - precision: 0.0627 - val_loss: 2.9322 - val_categorical_accuracy: 0.0796 - val_recall: 0.6742 - val_precision: 0.0625\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9318 - categorical_accuracy: 0.0879 - recall: 0.6507 - precision: 0.0627\n",
      "Epoch 19: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.11436202904824602\n",
      "############## Validation F1 score :  0.11472903503865305\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9318 - categorical_accuracy: 0.0879 - recall: 0.6507 - precision: 0.0627 - val_loss: 2.9306 - val_categorical_accuracy: 0.0823 - val_recall: 0.6722 - val_precision: 0.0627\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9312 - categorical_accuracy: 0.0853 - recall: 0.6447 - precision: 0.0625\n",
      "Epoch 20: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.11392998995047227\n",
      "############## Validation F1 score :  0.11509894113005521\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9312 - categorical_accuracy: 0.0853 - recall: 0.6447 - precision: 0.0625 - val_loss: 2.9288 - val_categorical_accuracy: 0.0856 - val_recall: 0.6735 - val_precision: 0.0629\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9306 - categorical_accuracy: 0.0877 - recall: 0.6503 - precision: 0.0625\n",
      "Epoch 21: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.11408566256486\n",
      "############## Validation F1 score :  0.11536503900997178\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9306 - categorical_accuracy: 0.0877 - recall: 0.6503 - precision: 0.0625 - val_loss: 2.9294 - val_categorical_accuracy: 0.0810 - val_recall: 0.6768 - val_precision: 0.0631\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9258 - categorical_accuracy: 0.0915 - recall: 0.6538 - precision: 0.0630\n",
      "Epoch 22: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.11499532731859924\n",
      "############## Validation F1 score :  0.11517796993706034\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9258 - categorical_accuracy: 0.0915 - recall: 0.6538 - precision: 0.0630 - val_loss: 2.9267 - val_categorical_accuracy: 0.0783 - val_recall: 0.6828 - val_precision: 0.0629\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9279 - categorical_accuracy: 0.0877 - recall: 0.6524 - precision: 0.0628\n",
      "Epoch 23: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.1145496017298023\n",
      "############## Validation F1 score :  0.11446055653391451\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9279 - categorical_accuracy: 0.0877 - recall: 0.6524 - precision: 0.0628 - val_loss: 2.9262 - val_categorical_accuracy: 0.0856 - val_recall: 0.6702 - val_precision: 0.0626\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9264 - categorical_accuracy: 0.0911 - recall: 0.6545 - precision: 0.0627\n",
      "Epoch 24: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.11436305548211002\n",
      "############## Validation F1 score :  0.11453401487356744\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9264 - categorical_accuracy: 0.0911 - recall: 0.6545 - precision: 0.0627 - val_loss: 2.9247 - val_categorical_accuracy: 0.0803 - val_recall: 0.6821 - val_precision: 0.0625\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9246 - categorical_accuracy: 0.0890 - recall: 0.6651 - precision: 0.0634\n",
      "Epoch 25: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.11569357436196082\n",
      "############## Validation F1 score :  0.11500167392939549\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9246 - categorical_accuracy: 0.0890 - recall: 0.6651 - precision: 0.0634 - val_loss: 2.9239 - val_categorical_accuracy: 0.0796 - val_recall: 0.6821 - val_precision: 0.0628\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9228 - categorical_accuracy: 0.0878 - recall: 0.6608 - precision: 0.0632\n",
      "Epoch 26: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.11534275808211769\n",
      "############## Validation F1 score :  0.1144063114000063\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9228 - categorical_accuracy: 0.0878 - recall: 0.6608 - precision: 0.0632 - val_loss: 2.9232 - val_categorical_accuracy: 0.0790 - val_recall: 0.6835 - val_precision: 0.0624\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9229 - categorical_accuracy: 0.0876 - recall: 0.6619 - precision: 0.0633\n",
      "Epoch 27: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.11551286248823739\n",
      "############## Validation F1 score :  0.11449955609222094\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9229 - categorical_accuracy: 0.0876 - recall: 0.6619 - precision: 0.0633 - val_loss: 2.9233 - val_categorical_accuracy: 0.0823 - val_recall: 0.6802 - val_precision: 0.0625\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9227 - categorical_accuracy: 0.0871 - recall: 0.6660 - precision: 0.0635\n",
      "Epoch 28: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.11601130811282818\n",
      "############## Validation F1 score :  0.11575740503684721\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9227 - categorical_accuracy: 0.0871 - recall: 0.6660 - precision: 0.0635 - val_loss: 2.9226 - val_categorical_accuracy: 0.0737 - val_recall: 0.6934 - val_precision: 0.0631\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9209 - categorical_accuracy: 0.0887 - recall: 0.6637 - precision: 0.0632\n",
      "Epoch 29: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.11545642720459331\n",
      "############## Validation F1 score :  0.11456463236207691\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9209 - categorical_accuracy: 0.0887 - recall: 0.6637 - precision: 0.0632 - val_loss: 2.9234 - val_categorical_accuracy: 0.0823 - val_recall: 0.6775 - val_precision: 0.0626\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9211 - categorical_accuracy: 0.0886 - recall: 0.6654 - precision: 0.0635\n",
      "Epoch 30: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.11585546391651892\n",
      "############## Validation F1 score :  0.11522216337129486\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9211 - categorical_accuracy: 0.0886 - recall: 0.6654 - precision: 0.0635 - val_loss: 2.9225 - val_categorical_accuracy: 0.0829 - val_recall: 0.6788 - val_precision: 0.0630\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9183 - categorical_accuracy: 0.0896 - recall: 0.6651 - precision: 0.0635\n",
      "Epoch 31: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.11589041686940933\n",
      "############## Validation F1 score :  0.11507094423885275\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9183 - categorical_accuracy: 0.0896 - recall: 0.6651 - precision: 0.0635 - val_loss: 2.9223 - val_categorical_accuracy: 0.0796 - val_recall: 0.6835 - val_precision: 0.0628\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9199 - categorical_accuracy: 0.0904 - recall: 0.6682 - precision: 0.0633\n",
      "Epoch 32: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.11562620070620622\n",
      "############## Validation F1 score :  0.11492734511745055\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9199 - categorical_accuracy: 0.0904 - recall: 0.6682 - precision: 0.0633 - val_loss: 2.9223 - val_categorical_accuracy: 0.0803 - val_recall: 0.6928 - val_precision: 0.0627\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9185 - categorical_accuracy: 0.0892 - recall: 0.6684 - precision: 0.0636\n",
      "Epoch 33: val_categorical_accuracy did not improve from 0.61712\n",
      "Model Metric\n",
      "############## F1 score :  0.11621046376583245\n",
      "############## Validation F1 score :  0.11583898403212502\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9185 - categorical_accuracy: 0.0892 - recall: 0.6684 - precision: 0.0636 - val_loss: 2.9221 - val_categorical_accuracy: 0.0810 - val_recall: 0.7027 - val_precision: 0.0631\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.9193 - categorical_accuracy: 0.0865 - recall: 0.6698 - precision: 0.0635\n",
      "Epoch 34: val_categorical_accuracy did not improve from 0.61712\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9193 - categorical_accuracy: 0.0865 - recall: 0.6698 - precision: 0.0635 - val_loss: 2.9215 - val_categorical_accuracy: 0.0803 - val_recall: 0.6974 - val_precision: 0.0627\n",
      "Epoch 34: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1513f20359a0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_model.fit(X_train,y_train,epochs=100,validation_data=(X_cv,y_cv), batch_size=256,callbacks=all_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a7546cec-e1b4-4161-beb2-ecc4cae14133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload started and will continue reading any new data as it's added to the logdir.\n",
      "\n",
      "To stop uploading, press Ctrl-C.\n",
      "\n",
      "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/NYsgJxMGTqOh0qoU7Vm44g/\n",
      "\n",
      "\u001b[1m[2022-10-17T02:23:07]\u001b[0m Started scanning logdir.\n",
      "E1017 02:23:12.159245 22457108703040 uploader.py:1122] Attempted to re-upload existing blob.  Skipping.\n",
      "\u001b[1m[2022-10-17T02:23:14]\u001b[0m Total uploaded: 1608 scalars, 2342 tensors (1.6 MB), 1 binary objects (119.8 kB)\n",
      "\u001b[90mTotal skipped: 1 binary objects (98.3 kB)\n",
      "^C2K\u001b[33mListening for new data in logdir...\u001b[0m\u001b[0m\n",
      "\n",
      "\n",
      "Interrupted. View your TensorBoard at https://tensorboard.dev/experiment/NYsgJxMGTqOh0qoU7Vm44g/\n"
     ]
    }
   ],
   "source": [
    "!tensorboard dev upload --logdir logs --name Model_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7715be-8d51-4248-9971-551986bd5b65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
