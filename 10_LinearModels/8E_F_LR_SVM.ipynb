{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HExLQrE4ZxR"
   },
   "source": [
    "<h1><font color='blue'> 8E and 8F: Finding the Probability P(Y==1|X)</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LuKrFzC4ZxV"
   },
   "source": [
    "<h2><font color='Geen'> 8E: Implementing Decision Function of SVM RBF Kernel</font></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wES-wWN4ZxX"
   },
   "source": [
    "<font face=' Comic Sans MS' size=3>After we train a kernel SVM model, we will be getting support vectors and their corresponsing coefficients $\\alpha_{i}$\n",
    "\n",
    "Check the documentation for better understanding of these attributes: \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "<img src='https://i.imgur.com/K11msU4.png' width=500>\n",
    "\n",
    "As a part of this assignment you will be implementing the ```decision_function()``` of kernel SVM, here decision_function() means based on the value return by ```decision_function()``` model will classify the data point either as positive or negative\n",
    "\n",
    "Ex 1: In logistic regression After traning the models with the optimal weights $w$ we get, we will find the value $\\frac{1}{1+\\exp(-(wx+b))}$, if this value comes out to be < 0.5 we will mark it as negative class, else its positive class\n",
    "\n",
    "Ex 2: In Linear SVM After traning the models with the optimal weights $w$ we get, we will find the value of $sign(wx+b)$, if this value comes out to be -ve we will mark it as negative class, else its positive class.\n",
    "\n",
    "Similarly in Kernel SVM After traning the models with the coefficients $\\alpha_{i}$ we get, we will find the value of \n",
    "$sign(\\sum_{i=1}^{n}(y_{i}\\alpha_{i}K(x_{i},x_{q})) + intercept)$, here $K(x_{i},x_{q})$ is the RBF kernel. If this value comes out to be -ve we will mark $x_{q}$ as negative class, else its positive class.\n",
    "\n",
    "RBF kernel is defined as: $K(x_{i},x_{q})$ = $exp(-\\gamma ||x_{i} - x_{q}||^2)$\n",
    "\n",
    "For better understanding check this link: https://scikit-learn.org/stable/modules/svm.html#svm-mathematical-formulation\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z830CfMk4Zxa"
   },
   "source": [
    "## Task E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuBxHiCQ4Zxc"
   },
   "source": [
    "> 1. Split the data into $X_{train}$(60), $X_{cv}$(20), $X_{test}$(20)\n",
    "\n",
    "> 2. Train $SVC(gamma=0.001, C=100.)$ on the ($X_{train}$, $y_{train}$)\n",
    "\n",
    "> 3. Get the decision boundry values $f_{cv}$ on the $X_{cv}$ data  i.e. ` `$f_{cv}$ ```= decision_function(```$X_{cv}$```)```  <font color='red'>you need to implement this decision_function()</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fCgMNEvI4Zxf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_function(model,X_cv):\n",
    "    higher_dim_product= rbf_kernel(model.support_vectors_,X_cv,gamma=0.001) # Cant do direct dot product\n",
    "    weighted_sum = np.dot(model.dual_coef_,higher_dim_product)+ model.intercept_\n",
    "    return weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ANUNIqCe4Zxn"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=100, gamma=0.001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=100, gamma=0.001)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=100, gamma=0.001)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=5000, n_features=5, n_redundant=2,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
    "X_ ,X_test,y_,y_test = train_test_split(X,y,test_size=0.2)\n",
    "X_train,X_cv,y_train,y_cv = train_test_split(X_,y_,test_size=0.25)\n",
    "model = SVC(gamma = 0.001, C=100)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.04415572])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHie1zqH4Zxt"
   },
   "source": [
    "### Pseudo code\n",
    "\n",
    "clf = SVC(gamma=0.001, C=100.)<br>\n",
    "clf.fit(Xtrain, ytrain)\n",
    "\n",
    "<font color='green'>def</font> <font color='blue'>decision_function</font>(Xcv, ...): #use appropriate parameters <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color='green'>for</font> a data point $x_q$ <font color='green'>in</font> Xcv: <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color='grey'>#write code to implement $(\\sum_{i=1}^{\\text{all the support vectors}}(y_{i}\\alpha_{i}K(x_{i},x_{q})) + intercept)$, here the values $y_i$, $\\alpha_{i}$, and $intercept$ can be obtained from the trained model</font><br>\n",
    "   <font color='green'>return</font> <font color='grey'><i># the decision_function output for all the data points in the Xcv</i></font>\n",
    "    \n",
    "fcv = decision_function(Xcv, ...)  <i># based on your requirement you can pass any other parameters </i>\n",
    "\n",
    "<b>Note</b>: Make sure the values you get as fcv, should be equal to outputs of clf.decision_function(Xcv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "h43kDT3M41u5"
   },
   "outputs": [],
   "source": [
    "# you can write your code here\n",
    "y_model_cv = model.decision_function(X_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_custom_cv = decision_function(model,X_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0bKCboN4Zxu"
   },
   "source": [
    "<h2><font color='Geen'> 8F: Implementing Platt Scaling to find P(Y==1|X)</font></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMn7OEN94Zxw"
   },
   "source": [
    "Check this <a href='https://drive.google.com/open?id=133odBinMOIVb_rh_GQxxsyMRyW-Zts7a'>PDF</a>\n",
    "<img src='https://i.imgur.com/CAMnVnh.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0n5EFkx4Zxz"
   },
   "source": [
    "## TASK F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0HOqVJq4Zx1"
   },
   "source": [
    "\n",
    "> 4. Apply SGD algorithm with ($f_{cv}$, $y_{cv}$) and find the weight $W$ intercept $b$ ```Note: here our data is of one dimensional so we will have a one dimensional weight vector i.e W.shape (1,)``` \n",
    "\n",
    "> Note1: Don't forget to change the values of $y_{cv}$ as mentioned in the above image. you will calculate y+, y- based on data points in train data\n",
    "\n",
    "> Note2: the Sklearn's SGD algorithm doesn't support the real valued outputs, you need to use the code that was done in the `'Logistic Regression with SGD and L2'` Assignment after modifying loss function, and use same parameters that used in that assignment.\n",
    "<img src='https://i.imgur.com/zKYE9Oc.png'>\n",
    "if Y[i] is 1, it will be replaced with y+ value else it will replaced with y- value\n",
    "\n",
    "> 5. For a given data point from $X_{test}$, $P(Y=1|X) = \\frac{1}{1+exp(-(W*f_{test}+ b))}$ where ` `$f_{test}$ ```= decision_function(```$X_{test}$```)```, W and b will be learned as metioned in the above step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTY7z2bd4Zx2"
   },
   "source": [
    "__Note: in the above algorithm, the steps 2, 4 might need hyper parameter tuning, To reduce the complexity of the assignment we are excluding the hyerparameter tuning part, but intrested students can try that__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CM3odN1Z4Zx3"
   },
   "source": [
    "\n",
    "If any one wants to try other calibration algorithm istonic regression also please check these tutorials\n",
    "\n",
    "1. http://fa.bianp.net/blog/tag/scikit-learn.html#fn:1\n",
    "\n",
    "2. https://drive.google.com/open?id=1MzmA7QaP58RDzocB0RBmRiWfl7Co_VJ7\n",
    "\n",
    "3. https://drive.google.com/open?id=133odBinMOIVb_rh_GQxxsyMRyW-Zts7a\n",
    "\n",
    "4. https://stat.fandom.com/wiki/Isotonic_regression#Pool_Adjacent_Violators_Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(row_vector):\n",
    "    ''' In this function, we will initialize our weights and bias'''\n",
    "    w = np.zeros(row_vector.shape)\n",
    "    b = 0\n",
    "    return w,b\n",
    "\n",
    "def sigmoid(z):\n",
    "    ''' In this function, we will return sigmoid of z'''\n",
    "    return 1/(1+np.exp(-z)) \n",
    "\n",
    "def logloss(y_true,y_pred):\n",
    "    ''' Return logloss once'''\n",
    "    if len(y_true) == 0 or len(y_pred) == 0:\n",
    "        return -1\n",
    "    loss = -1*np.sum(np.log10(y_pred)*y_true + (1-y_true)*np.log10(1-y_pred))/len(y_true)\n",
    "    return loss\n",
    "\n",
    "def gradient_dw(x,y,w,b,alpha,N):\n",
    "    '''In this function, we will compute the gardient w.r.to w '''\n",
    "    dw = x*(y - sigmoid(np.dot(w,x)+b)) - alpha*w/N\n",
    "    return dw\n",
    "\n",
    "def gradient_db(x,y,w,b):\n",
    "    '''In this function, we will compute gradient w.r.to b '''\n",
    "    db = (y - sigmoid(np.dot(w,x)+b))\n",
    "    return db\n",
    "\n",
    "def pred(w,b, X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        z=np.dot(w,X[i])+b\n",
    "        predict.append(sigmoid(z))\n",
    "    return np.array(predict)\n",
    "def train(X_train,y_train,X_test,y_test,epochs,alpha,eta0):\n",
    "    ''' In this function, we will learn weights and biases of logistic regression'''\n",
    "    \n",
    "    w,b = initialize_weights(X_train[0])    \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    w,b = initialize_weights(X_train[0]) \n",
    "    \n",
    "    for i in tqdm(range(epochs)):\n",
    "      \n",
    "        for i in range(X_train.shape[0]):# No rows is shape 0 \n",
    "            #compute gradient w.r.to w (call the gradient_dw() function)\n",
    "            dw = gradient_dw(X_train[i],y_train[i],w,b,alpha,X_train.shape[1])\n",
    "            #compute gradient w.r.to b (call the gradient_db() function)\n",
    "            db = gradient_db(X_train[i],y_train[i],w,b)\n",
    "            #update w, b\n",
    "            w += dw*eta0\n",
    "            b += db*eta0\n",
    "        #After each epoch collect train and test error \n",
    "        pred_train = pred(w,b,X_train)\n",
    "        pred_test  = pred(w,b,X_test) \n",
    "        train_step_loss = logloss(y_train,pred_train)\n",
    "        test_step_loss = logloss(y_test,pred_test)\n",
    "        \n",
    "        train_loss.append(train_step_loss)\n",
    "        test_loss.append(test_step_loss)\n",
    "\n",
    "    return w,b,train_loss,test_loss\n",
    "\n",
    "def plotError(train_loss,test_loss):\n",
    "    plt.plot([i for i in range(len(train_loss))],train_loss,color='blue',label=\"train error\")\n",
    "    plt.plot([i for i in range(len(train_loss))],test_loss,color='red',label=\"test error\")\n",
    "    plt.xlabel(\"Number of epochs ->\")\n",
    "    plt.ylabel(\"log-loss ->\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_param(w,b,x):# here w and b are scalar\n",
    "    return np.reciprocal(np.exp(w*x+b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1] [2088  912]\n"
     ]
    }
   ],
   "source": [
    "output_svm = y_custom_cv\n",
    "y_modified = []\n",
    "val,count = np.unique(y_train,return_counts=True)\n",
    "print(val,count)\n",
    "Np = count[1]\n",
    "Nv = count[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_modified = np.array([ 1/(Nv+2) if pt==0 else (Np+1)/(Np+2) for pt in y_cv ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 30/30 [00:00<00:00, 53.62it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "w,b,train_loss,test_loss = train(output_svm.T,y_modified,X_test=[],y_test=[],epochs=30,alpha=1e-03,eta0=1e-03)\n",
    "plotError(train_loss,test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.93124094]), -0.1792083120329727)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(X_test,w,b):\n",
    "    svm_output = decision_function(model,X_test)\n",
    "    return sigmoid_param(svm_output,w,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "probablity_outputs = output(X_test,w,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(probablity_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11206519, 0.13576784, 0.09681148, 0.23275949, 0.08195792,\n",
       "        0.07826748, 0.08258492, 0.09258825, 0.18959439, 0.16399742,\n",
       "        0.19698099, 0.10196127, 0.15154232, 0.18752576, 0.09269883,\n",
       "        0.0861851 , 0.09520361, 0.20576605, 0.16957541, 0.16122286,\n",
       "        0.20467927, 0.10446771, 0.07363876, 0.09877441, 0.08407238,\n",
       "        0.1763851 , 0.12461559, 0.08540894, 0.20271423, 0.08262616,\n",
       "        0.21430671, 0.09541281, 0.10558429, 0.13273845, 0.10360581,\n",
       "        0.14268446, 0.10909217, 0.21995317, 0.05724881, 0.09503206,\n",
       "        0.09882781, 0.17955062, 0.08751332, 0.09478021, 0.08506761,\n",
       "        0.13716397, 0.10344999, 0.22079206, 0.11280849, 0.16764642,\n",
       "        0.19802147, 0.10943894, 0.12755117, 0.15173819, 0.08116814,\n",
       "        0.08862289, 0.16937273, 0.13899021, 0.09074448, 0.11159591,\n",
       "        0.16794287, 0.0801576 , 0.20514399, 0.1283952 , 0.17835338,\n",
       "        0.08139338, 0.22236161, 0.06151593, 0.19629504, 0.09882738,\n",
       "        0.09102057, 0.15823596, 0.08099483, 0.11303405, 0.1017613 ,\n",
       "        0.14612576, 0.08732477, 0.08818792, 0.10822586, 0.10247438,\n",
       "        0.09544409, 0.1069481 , 0.0973547 , 0.08771408, 0.1097772 ,\n",
       "        0.22695167, 0.10178885, 0.08668757, 0.12242415, 0.08874679,\n",
       "        0.077498  , 0.19788775, 0.08654581, 0.19575496, 0.09166663,\n",
       "        0.12120797, 0.09203308, 0.07944369, 0.07701035, 0.1778202 ,\n",
       "        0.09084409, 0.16335151, 0.08741541, 0.10896476, 0.1675633 ,\n",
       "        0.07043954, 0.11451187, 0.16547678, 0.10001779, 0.09737256,\n",
       "        0.09537864, 0.20886381, 0.18074807, 0.10738579, 0.19513753,\n",
       "        0.09395875, 0.08992697, 0.08851591, 0.13412702, 0.08610898,\n",
       "        0.11616932, 0.18140876, 0.20559851, 0.08572955, 0.0924454 ,\n",
       "        0.07598706, 0.09434676, 0.09552651, 0.17713637, 0.2047607 ,\n",
       "        0.08607024, 0.10959414, 0.07550192, 0.21756379, 0.10647263,\n",
       "        0.0989218 , 0.09225791, 0.09328248, 0.15657605, 0.18563197,\n",
       "        0.07096686, 0.19601206, 0.09506842, 0.18704293, 0.10025621,\n",
       "        0.08705407, 0.07561312, 0.10773455, 0.12574886, 0.09143041,\n",
       "        0.07593709, 0.07124275, 0.10163115, 0.11354564, 0.12933439,\n",
       "        0.1222024 , 0.08814746, 0.09264956, 0.10478823, 0.22212595,\n",
       "        0.20905972, 0.08935211, 0.08703251, 0.11151607, 0.12750009,\n",
       "        0.19397907, 0.19369855, 0.170351  , 0.13220855, 0.08254751,\n",
       "        0.19950865, 0.08171161, 0.1296846 , 0.21352868, 0.12573748,\n",
       "        0.08576044, 0.08585568, 0.22967546, 0.17252267, 0.106485  ,\n",
       "        0.09640706, 0.18674784, 0.1032283 , 0.10816247, 0.20012477,\n",
       "        0.09600986, 0.08692073, 0.20562292, 0.09026209, 0.11122695,\n",
       "        0.16301448, 0.18526551, 0.1091368 , 0.10720481, 0.08785567,\n",
       "        0.18806809, 0.13949553, 0.08545747, 0.1412637 , 0.09663926,\n",
       "        0.10483181, 0.11659637, 0.07849327, 0.08548701, 0.15012963,\n",
       "        0.11205826, 0.19137231, 0.19056976, 0.10808623, 0.20872583,\n",
       "        0.15462449, 0.17607163, 0.08254163, 0.09189944, 0.11192149,\n",
       "        0.08913638, 0.09479012, 0.17627157, 0.15792899, 0.1164108 ,\n",
       "        0.10538006, 0.13058007, 0.12751552, 0.08565513, 0.20130821,\n",
       "        0.11203847, 0.08891249, 0.07630578, 0.12924424, 0.06474553,\n",
       "        0.08077932, 0.07193459, 0.13522791, 0.08567632, 0.08867076,\n",
       "        0.11820848, 0.09667118, 0.09663209, 0.11246556, 0.09209839,\n",
       "        0.15238364, 0.11088281, 0.09976957, 0.12418904, 0.09492079,\n",
       "        0.08669894, 0.21409782, 0.14286692, 0.09243309, 0.08303088,\n",
       "        0.07955313, 0.1896386 , 0.08818388, 0.18683113, 0.19805163,\n",
       "        0.08140533, 0.08771388, 0.18261593, 0.08213291, 0.103629  ,\n",
       "        0.10027441, 0.19984797, 0.19776011, 0.11848473, 0.1542518 ,\n",
       "        0.16273771, 0.10939403, 0.08096497, 0.11095426, 0.11098945,\n",
       "        0.0923674 , 0.09530829, 0.10975023, 0.12746035, 0.08857297,\n",
       "        0.20745483, 0.14845104, 0.11366432, 0.09526983, 0.09089132,\n",
       "        0.0835236 , 0.09021421, 0.08483645, 0.19246331, 0.07299971,\n",
       "        0.11142164, 0.17533145, 0.09591893, 0.17961924, 0.15660906,\n",
       "        0.17720936, 0.21629776, 0.08920552, 0.18444344, 0.19665463,\n",
       "        0.17235016, 0.12184002, 0.19579174, 0.12618275, 0.11797796,\n",
       "        0.07279415, 0.20059575, 0.10773859, 0.10948311, 0.09006794,\n",
       "        0.24923829, 0.13672009, 0.09051628, 0.10079841, 0.23543071,\n",
       "        0.09499896, 0.09302038, 0.16084069, 0.09584015, 0.09568741,\n",
       "        0.2047603 , 0.27628506, 0.08580448, 0.10468222, 0.14790255,\n",
       "        0.10610074, 0.13395311, 0.11041086, 0.19763545, 0.20115469,\n",
       "        0.18100735, 0.13297822, 0.09593609, 0.16093015, 0.16880436,\n",
       "        0.07363431, 0.18394736, 0.11985856, 0.11651201, 0.0808147 ,\n",
       "        0.09952678, 0.19328227, 0.10686187, 0.21208127, 0.14141042,\n",
       "        0.19155634, 0.16974669, 0.0883568 , 0.07383297, 0.13248254,\n",
       "        0.0763129 , 0.09525173, 0.08571704, 0.07871024, 0.08138599,\n",
       "        0.15033535, 0.17119981, 0.09313836, 0.17138273, 0.10408224,\n",
       "        0.09411171, 0.11675541, 0.17618485, 0.07585823, 0.06914297,\n",
       "        0.17340007, 0.08134117, 0.17031167, 0.19786642, 0.10719595,\n",
       "        0.11740301, 0.12664107, 0.14035377, 0.06252489, 0.07341718,\n",
       "        0.09531744, 0.12634112, 0.22397733, 0.18674235, 0.09855995,\n",
       "        0.1979442 , 0.19645411, 0.22382913, 0.0858245 , 0.13690875,\n",
       "        0.13231152, 0.12837645, 0.09232193, 0.08781514, 0.20971728,\n",
       "        0.10529253, 0.20319246, 0.09348457, 0.05388525, 0.0873113 ,\n",
       "        0.09615697, 0.08537773, 0.19405036, 0.09933208, 0.09301052,\n",
       "        0.07339554, 0.1959082 , 0.12203409, 0.11124671, 0.09196567,\n",
       "        0.10894448, 0.21694667, 0.19065825, 0.05764001, 0.08776116,\n",
       "        0.09724857, 0.07865875, 0.14695253, 0.11006431, 0.15053342,\n",
       "        0.0966364 , 0.12850644, 0.19457176, 0.19632961, 0.17602645,\n",
       "        0.08404657, 0.15975683, 0.1526973 , 0.19669352, 0.11534597,\n",
       "        0.10260211, 0.22990626, 0.12164543, 0.19127174, 0.18406802,\n",
       "        0.07393764, 0.09695633, 0.11812614, 0.15647736, 0.20867943,\n",
       "        0.20137046, 0.19244216, 0.09296006, 0.18258294, 0.17958467,\n",
       "        0.21014838, 0.19437223, 0.10396178, 0.19646787, 0.07911778,\n",
       "        0.10624137, 0.0819712 , 0.14449019, 0.08585875, 0.08728464,\n",
       "        0.10271477, 0.08469255, 0.08822516, 0.09114542, 0.07874674,\n",
       "        0.08382032, 0.09720359, 0.09569898, 0.10159123, 0.19381415,\n",
       "        0.06459623, 0.08429767, 0.08913086, 0.10114448, 0.25587937,\n",
       "        0.09391913, 0.09623442, 0.09352649, 0.10759441, 0.07985857,\n",
       "        0.13162422, 0.08516134, 0.20100926, 0.12778219, 0.2226294 ,\n",
       "        0.2039893 , 0.11854462, 0.18691468, 0.18382341, 0.09305915,\n",
       "        0.20844118, 0.09620053, 0.10740305, 0.09741188, 0.08638451,\n",
       "        0.10936142, 0.13344451, 0.09993743, 0.11325728, 0.11197252,\n",
       "        0.23258101, 0.08664333, 0.10322581, 0.16963818, 0.09345671,\n",
       "        0.19340193, 0.19988369, 0.09062216, 0.08861348, 0.09420657,\n",
       "        0.09327124, 0.08906251, 0.07405573, 0.22324056, 0.1558289 ,\n",
       "        0.11379891, 0.14122399, 0.08532866, 0.20812635, 0.08164432,\n",
       "        0.20417097, 0.22104054, 0.19207908, 0.09049544, 0.18823402,\n",
       "        0.09677645, 0.07833928, 0.17504301, 0.12850498, 0.08644774,\n",
       "        0.10935028, 0.07647897, 0.22136022, 0.15176565, 0.18894863,\n",
       "        0.11225411, 0.08400879, 0.10752874, 0.0960284 , 0.09384665,\n",
       "        0.06740688, 0.08664785, 0.20876237, 0.16732144, 0.07798563,\n",
       "        0.11055574, 0.13471393, 0.19440434, 0.07481864, 0.10482964,\n",
       "        0.08792712, 0.19900469, 0.20881236, 0.08682623, 0.08391599,\n",
       "        0.25042281, 0.10802227, 0.10733153, 0.19461571, 0.08202641,\n",
       "        0.20708966, 0.08248129, 0.06861257, 0.14545681, 0.18431983,\n",
       "        0.15262391, 0.25694409, 0.18020148, 0.16902967, 0.10012212,\n",
       "        0.08956781, 0.09698407, 0.18721115, 0.21306463, 0.21276731,\n",
       "        0.08106884, 0.09196451, 0.09829981, 0.19050888, 0.20670697,\n",
       "        0.17840019, 0.18255419, 0.09477461, 0.10395798, 0.0911473 ,\n",
       "        0.13184076, 0.07477371, 0.10726089, 0.08533009, 0.0618717 ,\n",
       "        0.18508623, 0.10313216, 0.17801687, 0.0949738 , 0.20041663,\n",
       "        0.14422153, 0.08448092, 0.08835893, 0.1441858 , 0.12354423,\n",
       "        0.18831709, 0.10785564, 0.11453897, 0.07733958, 0.12146127,\n",
       "        0.10403195, 0.09508037, 0.09240944, 0.07232469, 0.17073286,\n",
       "        0.15739928, 0.18451973, 0.17314578, 0.08547659, 0.09013982,\n",
       "        0.07407773, 0.20839697, 0.107342  , 0.10225762, 0.09075874,\n",
       "        0.24403425, 0.06782424, 0.18643705, 0.09670921, 0.22381926,\n",
       "        0.1346967 , 0.09008904, 0.19067271, 0.09563004, 0.12799937,\n",
       "        0.11695015, 0.20150909, 0.14391761, 0.09311534, 0.19786953,\n",
       "        0.08929127, 0.1063919 , 0.09495912, 0.18692629, 0.12282777,\n",
       "        0.17207943, 0.09275336, 0.13008447, 0.07494114, 0.06692765,\n",
       "        0.17386224, 0.0880668 , 0.07869984, 0.20631633, 0.14534007,\n",
       "        0.1736078 , 0.09525155, 0.11260184, 0.08226523, 0.08532721,\n",
       "        0.10677803, 0.10098202, 0.09199923, 0.0812081 , 0.09095088,\n",
       "        0.1066395 , 0.07022758, 0.21474953, 0.16107858, 0.21105495,\n",
       "        0.11141745, 0.07988403, 0.12426471, 0.17482409, 0.07676557,\n",
       "        0.09524262, 0.08803769, 0.09196271, 0.09971824, 0.07761405,\n",
       "        0.0984237 , 0.1370746 , 0.16920331, 0.20459462, 0.17840351,\n",
       "        0.07725349, 0.08249224, 0.16242113, 0.0901576 , 0.08321225,\n",
       "        0.09814066, 0.08734801, 0.07197472, 0.10669774, 0.09637593,\n",
       "        0.07453823, 0.10035966, 0.19530486, 0.08033593, 0.08331411,\n",
       "        0.21092523, 0.15862707, 0.21351468, 0.10023868, 0.20084165,\n",
       "        0.12119775, 0.09560975, 0.10577321, 0.11556757, 0.09859969,\n",
       "        0.11085673, 0.08697196, 0.10333219, 0.1744237 , 0.102606  ,\n",
       "        0.09712208, 0.11214697, 0.1886145 , 0.14017679, 0.19991424,\n",
       "        0.09457526, 0.0867452 , 0.0825397 , 0.16256638, 0.07396988,\n",
       "        0.11479364, 0.10022691, 0.10245389, 0.1036445 , 0.18984491,\n",
       "        0.17612996, 0.09734427, 0.12665285, 0.19100362, 0.10445466,\n",
       "        0.06922682, 0.14478302, 0.21958443, 0.08550155, 0.05713247,\n",
       "        0.09711273, 0.21579332, 0.21741237, 0.07807379, 0.07276195,\n",
       "        0.09176314, 0.10289113, 0.10897232, 0.12328192, 0.2063028 ,\n",
       "        0.1534457 , 0.27647077, 0.0842458 , 0.08714573, 0.07870625,\n",
       "        0.07992373, 0.09425506, 0.09396636, 0.06831386, 0.08257679,\n",
       "        0.1048636 , 0.20493889, 0.09847551, 0.17912171, 0.12676003,\n",
       "        0.0885361 , 0.10459343, 0.10094353, 0.18970211, 0.20766347,\n",
       "        0.07872059, 0.08441905, 0.19868413, 0.12250109, 0.1503199 ,\n",
       "        0.083347  , 0.1502826 , 0.15003414, 0.12959744, 0.12966909,\n",
       "        0.10876979, 0.11716873, 0.09097015, 0.09068884, 0.13272227,\n",
       "        0.17270599, 0.07389932, 0.094717  , 0.08003795, 0.08837753,\n",
       "        0.09070397, 0.20701469, 0.08197579, 0.08126889, 0.17786985,\n",
       "        0.09828227, 0.10617255, 0.09818653, 0.24874672, 0.10248633,\n",
       "        0.07520344, 0.20699045, 0.08358814, 0.16464019, 0.12594959,\n",
       "        0.20372658, 0.17543258, 0.10341811, 0.19191215, 0.10007535,\n",
       "        0.0989073 , 0.18275892, 0.09967566, 0.08870215, 0.12034713,\n",
       "        0.19412255, 0.08425732, 0.08689143, 0.09011323, 0.08836531,\n",
       "        0.08458657, 0.07888668, 0.20092192, 0.08725904, 0.09706941,\n",
       "        0.12053112, 0.10937544, 0.20577971, 0.08638013, 0.16327352,\n",
       "        0.10414237, 0.10458182, 0.10816031, 0.09094815, 0.0968537 ,\n",
       "        0.10824449, 0.10847792, 0.20612514, 0.22497823, 0.09365144,\n",
       "        0.07840115, 0.18901553, 0.12382253, 0.07434356, 0.10949287,\n",
       "        0.13722345, 0.10661728, 0.18086011, 0.14763081, 0.09540367,\n",
       "        0.13332227, 0.21044079, 0.10705729, 0.09124719, 0.11877997,\n",
       "        0.1886395 , 0.11275557, 0.10033374, 0.08603611, 0.09112406,\n",
       "        0.08610431, 0.1496814 , 0.09430521, 0.10139685, 0.17978072,\n",
       "        0.0826716 , 0.08538052, 0.11259675, 0.20651291, 0.21529164,\n",
       "        0.18534125, 0.10451599, 0.08246827, 0.10075155, 0.19209293,\n",
       "        0.09878307, 0.07516511, 0.0690631 , 0.2279671 , 0.19477016,\n",
       "        0.07847067, 0.08220007, 0.1766053 , 0.08251473, 0.12750338,\n",
       "        0.08667908, 0.09429538, 0.10766045, 0.1010725 , 0.20796463,\n",
       "        0.11138474, 0.10930855, 0.06729222, 0.09913418, 0.08577333,\n",
       "        0.08462426, 0.08565333, 0.14220162, 0.08798102, 0.10227564,\n",
       "        0.07853228, 0.10206262, 0.08322917, 0.11688786, 0.10033927,\n",
       "        0.17655124, 0.07907018, 0.12695196, 0.1751329 , 0.18587033,\n",
       "        0.10537075, 0.10097295, 0.08709793, 0.07789054, 0.08852836,\n",
       "        0.16713276, 0.17434284, 0.22629341, 0.10004412, 0.09078137,\n",
       "        0.12088075, 0.11414701, 0.08054564, 0.07259805, 0.06881502,\n",
       "        0.21518105, 0.19822374, 0.09036564, 0.12864212, 0.11889815,\n",
       "        0.18271086, 0.20096932, 0.16531386, 0.08136746, 0.07778408,\n",
       "        0.15000564, 0.15224604, 0.09661223, 0.12441791, 0.18075522,\n",
       "        0.06497996, 0.09342587, 0.07270977, 0.09582006, 0.07834923,\n",
       "        0.09040302, 0.09398887, 0.13637703, 0.14972541, 0.08863809,\n",
       "        0.06488192, 0.05828873, 0.08570301, 0.19256554, 0.11927395,\n",
       "        0.07988507, 0.1756845 , 0.18363022, 0.06563535, 0.12114659,\n",
       "        0.11508839, 0.08746965, 0.09647514, 0.08713104, 0.23133878,\n",
       "        0.08754874, 0.08394201, 0.19398703, 0.08198581, 0.09466997,\n",
       "        0.11386955, 0.27947175, 0.08217689, 0.22866307, 0.1004161 ,\n",
       "        0.13137386, 0.09512628, 0.08862292, 0.15443689, 0.12405403,\n",
       "        0.13684121, 0.07683473, 0.19873182, 0.08694632, 0.20667069,\n",
       "        0.15621657, 0.19490745, 0.11094309, 0.20775531, 0.10982756,\n",
       "        0.09156984, 0.07184636, 0.07059251, 0.09318421, 0.11519632,\n",
       "        0.12397584, 0.07517597, 0.21071894, 0.08080244, 0.07496615,\n",
       "        0.10530685, 0.09478689, 0.08133408, 0.0816807 , 0.08317933,\n",
       "        0.11777653, 0.07461299, 0.16565905, 0.09727401, 0.09006924,\n",
       "        0.16959458, 0.06998578, 0.18005879, 0.10937772, 0.09052676,\n",
       "        0.08815168, 0.09130052, 0.220565  , 0.09820475, 0.20290504]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probablity_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST AUC SCORE 0.9806010524859374\n"
     ]
    }
   ],
   "source": [
    "test = roc_curve(y_test, probablity_outputs[0])# this returns a list which is the order of [false_postive_rate,true_positive_rate,thresholds]\n",
    "print(\"TEST AUC SCORE\",roc_auc_score(y_test, probablity_outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(test[0],test[1],label=\"Test\",color='red')\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "8E&F_LR_SVM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
